{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\RAG using langchain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader,PyPDFLoader,UnstructuredWordDocumentLoader,TextLoader,UnstructuredHTMLLoader,UnstructuredMarkdownLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "# Initialize Hugging Face embedding\n",
    "hugging_face_ef = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=HF_TOKEN,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "llm_model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# pdf\n",
    "pdf_loader = DirectoryLoader(directory_path, glob=\"**/*.pdf\", loader_cls=PyPDFLoader,show_progress=True,use_multithreading=True)\n",
    "pdf_docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# txt\n",
    "txt_loader = DirectoryLoader(directory_path, glob=\"**/*.txt\",loader_cls=TextLoader,show_progress=True,use_multithreading=True)\n",
    "txt_docs = txt_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:33<00:00, 33.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# md\n",
    "md_loader = DirectoryLoader(directory_path, glob=\"**/*.md\",loader_cls=UnstructuredMarkdownLoader,show_progress=True,use_multithreading=True)\n",
    "md_docs = md_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# docx\n",
    "docx_loader = DirectoryLoader(directory_path, glob=\"**/*.docx\",loader_cls=UnstructuredWordDocumentLoader,show_progress=True,use_multithreading=True)\n",
    "docx_docs = docx_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n"
     ]
    }
   ],
   "source": [
    "html_loader = DirectoryLoader(directory_path, glob=\"**/*.html\",loader_cls=UnstructuredHTMLLoader,show_progress=True,use_multithreading=True)\n",
    "html_docs = html_loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10}, page_content=\"• AR content optimization: Improvement in the delivery of AR content through enhancements in adaptive\\nsystems so that sensitivity to the viewer's proximity and angle of view is greatly enhanced to ﬁlter the\\ncontext so that the amount of appearing content is user-friendly.  Using customization attributes that\\nincorporate recommendation and gamiﬁcation, and also personalizing the content to the person, will make\\nthe AR-based food application more interactive for users. \\n• Therefore, the drivers of this gap between healthy intentions and actual behavior of users, will therefore\\nlead to better tools for the facilitation of healthier choice. \\n• Expanding ingredient libraries: The further an ingredient database is expanded with local and cultural\\ningredients, the more ingredient-substitution systems will both accurately and more appropriately react to\\ndiverse diets. AI and Machine Learning: AI-based personalization and prediction upgrade the food apps'\\nbrains to give smart suggestions and perfect substitutes for ingredients. Advanced data structures, such as\\na knowledge graph, make this system even more accurate. \\n \\nDISCUSSION\\nAnalyzing the contents in nutritional content and detecting allergens is a dimension of food ingredient\\nanalysis integrating AI with AR, on the cutting edge of digital health advancements. Real-time, interactive\\nanalysis can be made through applications that combine AI image recognition and machine learning\\ncapabilities with AR's immersion in interface design, hence opening access to detailed information on the\\ningredients instantaneously. This has proved very useful for people with dietary restrictions, allergies, or\\nchronic conditions since it promotes safer and more informed food choices.\\nThere are, however several challenges and limitations that arise in such attempts. Ingredient recognition\\noften gets aﬀected by environmental conditions such as lighting, food appearance, and packaging that make\\nAI models less reliable for such a data. It also comprises the complexity of producing a comprehensive food\\ndatabase. It demands the extensive collaboration and resources to support accurate analysis by cross-\\ncultural and regional food items. An important limitation in AI-based AR applications is the collection of\\nsensitive data, which varies for each app to enable user-speciﬁc recommendations, raising data privacy\\nissues. Data privacy rules and regulation require to ensure the protection of user data and generate trust\\namong users.\\nA key aspect of it is user experience, in the sense of intuitive and easy use towards broad adoption. Simpler\\ninterfaces and smoother integration into daily life will improve usability, but further developments in wearable\\nAR devices could make ingredient analysis even more accessible and convenient.\\nOther potential research directions include optimizing the performance of AI models, scaling databases to\\naccommodate an even greater variety of global foods, and enhancing data privacy. There are also larger\\npopulation health implications, such as a possible decrease in diet-related diseases and increased dietary\\nawareness through the use of AI-based AR applications. AI-based AR for analyzing food ingredients is still\\ndeveloping but promises much opportunity for revolutionizing nutrition management, making this practice-\\nassisted decision-making valuable for leading healthier lifestyles and hopefully achieving better public health\\noutcomes.\\nAdditional Information\\nDisclosures\\nConﬂicts of interest:\\n In compliance with the ICMJE uniform disclosure form, all authors declare the\\nfollowing: \\nPayment/services info:\\n All authors have declared that no ﬁnancial support was received from\\nany organization for the submitted work. \\nFinancial relationships:\\n All authors have declared that they have\\nno ﬁnancial relationships at present or within the previous three years with any organizations that might\\nhave an interest in the submitted work. \\nOther relationships:\\n All authors have declared that there are no\\nother relationships or activities that could appear to have inﬂuenced the submitted work.\\nAcknowledgements\\nWe would like to express our sincere gratitude to our guide, Prof. (Mrs.) Shobha. S. Raskar, for their\\ninvaluable \\nsupport, guidance, and encouragement throughout the course of this project. Their expertise and\\ninsights \\nwere instrumental in shaping our understanding of ML and AR technologies. \\nAdditionally, we\\nextend our thanks to our colleagues and peers who provided constructive feedback and \\nsupport during this\\nendeavor.\\nReferences\\n1\\n. \\nJuhwan Lee, Sangwon Hwang, Jisun Lee, Seungwoo Kang: \\nComparative Performance Characterization of\\nMobile AR Frameworks in the Context of AR-Based Grocery Shopping Applications\\n. 2020, 10(4):1547.\\n Cureus Journal of Computer Science\\n11\\n of \\n12\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10}, page_content=\"• AR content optimization: ...\")\n",
    "\"\"\"\n",
    "pdf_docs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt'}, page_content=\"D. Food Ingredient Databases:\\nAccessible and comprehensive food ingredient databases are a benchmark for mobile applications meant to\\nenhance dietary choices and outcomes. It contains detailed data of food products, among which are the\\ningredients, nutritional values, and potential allergens. [4] One such example includes the open source\\ndatabase known as Open Food Facts, containing over 50,000 entries of food products present in 134\\ncountries. [5] However, often, custom databases need to be created with regard to specific requirements so\\nthat local food products may be covered. [8] \\nOne is PHARA, which uses a client-server architecture with a MongoDB database to implement\\nrecommendations of healthy foods. The database contains items as well as user profiles. It feeds this\\ninformation into the application's recommendation engine whereby consumers marked out healthier foods\\nthey liked and wanted by preference and need[5].\\nAnother application is regarding ingredient analysis especially concerning food allergies. This is done using\\na barcode scanner and OCR by scanning the ingredients against a food and health database having known\\nallergens. Ingredients scanned will alert the users on those materials that can cause allergic reactions. [5] \\nARFusion is the grocery shopping application enabled with AR based on a health-based model of nutrition,\\nand has personal and family profiles filled into it. It requires relating data from product database tracking\\ninformation of every product's ingredient, nutrient, and the location in the grocery, which information allows\\nthe application to make real-time personalized recommendations on healthy products. [9] \\nMoreover, the substitution of ingredients is performed using knowledge graphs. One such system was\\ncreated based on a knowledge graph called FoodKG which interconnected the ingredients with the food\\nontology named FoodOn and even nutritional information by USDA. This system points out healthy\\nalternatives according to dietary restrictions. [10] \\nTherefore, there is a great need to establish such comprehensive food ingredient databases that would be\\naccessible for consumers so that they might choose their foods wisely, where they would enjoy better habits\\nof consumption and general well-being. [4] \\nE. UI/UX in Food-Related Mobile Applications: A Balancing Act\\nBut of both, what shines through is the role that well-designed UIs and UXs play especially for the mobile\\napplications concerning food. Rather more salient considerations piling too much information on users or\\ntaking them through complicated navigation is more nuisance to engagement and effectiveness resulting\\nfrom balancing clamor for quick and easy access of such applications. \\nOne of the ways through which complicated information can be made accessible is through visual, such as\\ncolor-coded tags and intuitive layouts. The result of the study was that the color-coded AR tags were very\\neasy for the users to distinguish between the healthy and unhealthy products. The developers of the\\nPHARA attempted to develop modular visual parts that would pass relevant information in a clear-cut\\nCureus Journal of Computer Science\\n5 of 12\\nmanner. Figure 8 of this source shows several layouts of PHARA in making food product information\\nunderstandable. [3]  \\nFor example, the design of a mobile application concerning the ingredient analysis is essential to make sure\\nit becomes user friendly, considering there are food allergic users who might at some point require\\nassistance. The interface of the application focused on simplicity in daily use. [3] \\nTherefore, developers have to face the specific functional-related issues pertaining to such applications. For\\nexample, food scanner applications require one to scan the barcodes of each article purchased in the\\nmarket. It is cumbersome and time-consuming in the process. These features, combined with overall\\ninformation regarding nutritional content usually available, pose a burdensome job for the user to go through\\nthe information and take the right decisions. [3] \\nOn the contrary, FOP labels present a much less complicated approach. FOP labeling acquires the real\\nsimplified nutritional information on product packaging. This ease of access and processing becomes a\\ngood reason why FOP labels are more effective in determining consumer choices compared to food scanner\\napps. [11] \\nAnother great UI/UX is restaurant AR menus. With restaurant AR, the wish of the customers can be\\nsatisfied with three-dimensional images of dishes and even whole lists of ingredients; the menu can be\\ninteractive. The value of the information should be conserved rather than speed up the generation of the\\ncontent. In order to get success, the entire AR experience has to be intuitive as well as informative. [4] \\nMore generally, the sources emphasize that the development of successful food-related mobile apps will\\nrequire special attention to UI/UX principles. Balancing 'complexity' of features with the need for a seamless\\nuser experience is key to user engagement and, in the end, the impact of the app toward changing users'\\nhealthy choices.\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt'}, page_content=\"D. Food Ingredient Databases:...\")\n",
    "\"\"\"\n",
    "txt_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\ar_influence_on_market.md'}, page_content=\"AR's Influence on Consumer Behavior: Potential and Pitfalls\\n\\nSources investigate the effects of Augmented Reality on consumer behavior, from developing the shopping experience to more challenges entailed in increasing complexity and ease of use. Although AR brings some innovative ways of interaction with the consumer in order to provide information, effectiveness is lower than the other, much more common influences, such as FOP labels.\\n\\nImproving Food Choices Using Augmented Reality\\n\\nA number of studies demonstrate the potential of AR to encourage healthier food choices. A study [9] explored the feasibility of an AR application which gives users personalized suggestions of healthy products to purchase in supermarkets. The application identified shelf products and overlaid color-coded flags, thus allowing users to point out healthy foods quickly along with bad ones to avoid. Another app [1] aimed to guide consumers toward making healthier selections focusing on diet. It relied on the color-coded classification between healthy and unhealthy foods.\\n\\nSource [11] would propose an AR application, PHARA, to aid in grocery store food product choice decision-making. The application of AR is applied to represent information about food products to a user. Another study [1] uses a mobile application-based AR, which provides information to consumers on products using AR and suggests healthy and similar products to people.\\n\\nFurthermore, researchers [12] conducted four studies to investigate the influence of a food scanner app (Yuka) on consumer choice. They found that, whereas the app increased intentions to buy healthier products in hypothetical situations, it had no impact on real behavior in the grocery store itself during an experimental supermarket setting. This gap between intentions and actual choices also points to the effort which may be required to utilize it while shopping, thus constituting a barrier toward the effectiveness of the application of the app.\\n\\nAR vs Conventional Techniques\\n\\nAll these sources point out that in almost all conditions, consumer behavior affects AR interventions less compared to the traditional methods such as FOP labeling. A comparative study [7] where a head-to-head comparison of the app on the food scanner versus FOP labeling came out indicated that in all situations, FOP labeling always outscored the application.\\n\\nReasons for Differences in Performance:\\n\\nThere are several reasons that can explain differences in performance. FOPs give consumers a look from the front of the package nutrition information directly accessible and easy to process. With AR applications, especially if they require scanning the barcode, their use will require more effort from the user—which may interfere with the proper processing of the information or even reduce the making of an informed choice.\\n\\nSource [13] concludes that food scanner apps are ineffective as substitutes for FOP labels since the information is far more extensive and multiple scans are required for comparison of packaged products. Such multilevel processing of information might, in turn, sub-optimally affect consumers' choices.\\n\\nPotential Applications and Future Directions\\n\\nSources admit that, despite the problems in AR, it has uses and future directions.\\n\\nAR can be used to create interactive menus in restaurants so that customers can view three-dimensional visualizations of the dishes and the lists of ingredients in detail [4]. It may enhance customer engagement and possibly your customer choice.\\n\\nAR can be embedded in food packaging so that consumers get a rich interaction experience [4]. Scanning the packaging shall unlock for users information regarding the nutritional data, the origin, and the process of manufacture along with virtual representations of the food. Such enhanced transparency and engagement might impact the purchasing decision.\\n\\nAR applications can be further developed to aid in new food product development [4]. Developers can easily identify possible problems and then optimize a product for actual production by virtue of virtualization of the product followed by its analysis in real environments or simulated environments.\\n\\nFurther studies may be conducted to ascertain whether AR with other modes like FOP labels push consumers toward healthier diets [14]. Perhaps, in isolation, the strategy can do little but when merged, the constraints are crossed, and intervention becomes that much stronger. All levelled off, taken broadly, in a rather convex shape to reveal the impact of AR on consumer behavior. Promises of AR about enhancing shopping experiences and healthy choices seem alluringly good but simplifying complexity and ease of use seem the biggest hurdles. Further research and development of optimal applications are required in their realization as regards their potential in shaping consumer behavior.\")]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Document(metadata={'source': 'data\\\\ar_influence_on_market.md'}, page_content=\"AR's Influence on Consumer Behavior...\")]\n",
    "\"\"\"\n",
    "md_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\introduction_and_background.docx'}, page_content='Introduction And Background\\nINTRODUCTION\\nIt has been richly noted that information technology could catalyze an important set of benefits in the\\nhealthcare area which would include improving the quality and reducing the cost of healthcare. The\\nemergence of sensor-rich powerful smart phones to provide a rich set of user contextual information in real\\ntime made it feasible to provide effective and affordable healthcare to nearly everyone via smartphones.\\nMore specifically, well-designed mobile phone applications can empower individuals to proactively embrace\\nhealth and wellness. No longer is the health care system made of a reactive system or placed sitting back\\nwaiting for medical attention to surface via an ER visit. What once belonged to the clinic is now patient-\\ncentered care. What once focused on the disease agenda is now wellness in health care.\\nBased on the sheer number of excellent justifications for applying smartphones, cloud computing, mobile\\naugmented reality and other information technologies to improve health and well-being in society, this paper\\nexamines the interactive, creative, and user-friendly health mobile applications. Previous studies have\\nclearly established a correlation between low levels of nutritional intake and the rising prevalence of\\nunhealthy conditions such as obesity and lifestyle diseases such as heart disease and diabetes. A lack of\\nhealthy food consumption coupled with physical inactivity is two key causes of an epidemic of overweight\\npersons and cases of obesity in the United States. The betterment of a person\\'s diet begins with the\\nbetterment of the nutritional quality of food he or she chooses. This makes it nearly impossible for the\\naverage consumer to make better choices when a food supply contains tens of thousands of processed and\\npackaged foods with different messages on bags, boxes, bottles, jars, and cans. Consumers report they\\nknow what is healthy and what isn\\'t, but say they are confused over how to implement general nutritional\\nadvice.\\n\\n\\n\\n\\nThe application of technology in diet management has been perceived as a useful tool and resource in\\nhelping to reduce poor health conditions and foster good well-being generally among people. Mobile\\naugmented reality in supermarkets is one of the proposed solutions to this very pressing problem of\\nenriching the quality of nutrition in food choices while shopping at the point-of-sale. One of the more\\ninteresting emerging technologies AR exemplifies, in very simple words, simply offers rich visual interaction\\nwith the real world by overlaying or augmenting the elements the camera view contains with useful\\ninformation with relevance to the objects appearing in the video screen of the camera. With an AR-based\\nsmartphone application, the user now experiences a direct interactive or context-rich experience. Actually, it\\nis just recently that AR gained much mindshare as an exciting new technology for the mobile smartphone.[1]\\nSome examples of such applications are an augmented reality range finder for golf lovers, Cape GPS\\nRangefinder; AR application for color-blind people; Google Sky Map, that is an AR application for amateur\\n1 1 1 1\\n1\\n\\n\\n\\n\\nCureus Journal of Computer Science \\nOpen Access Review\\nArticle\\nHow to cite this article\\n\\nastronomers; Word Lens, that translates a foreign language captured by the mobile camera and overlays\\nthe result on top of the text; and many more. As the user continues walking down an aisle to get an item, its\\nAR tag grows in size. When the tags of the thing are clicked, it provides nutrition information about that\\nproduct. Tags are colored. Therefore, for example, green would be nutritionally preferable items-low calorie\\nand gluten-free. Red would be used to mark bad products to avoid. For example, those that have a high\\ncholesterol level or peanut contents. Additionally, the consumers can upload health profiles that might have\\nan influence on their purchasing of food products such as weight watch, heart condition, and food allergies,\\netc. We observe that the product to be recommended will differ because the user has provided an input\\nhealth condition/cue. To our knowledge system, we strongly believe that we are the first ones that introduce\\nAR tagging with pedometric-based localization along with back-end health-based grocery recommendation\\nat point of purchase.\\nPoint-of-purchase nutrition information probably would have greater impacts on dietary quality because it\\nbetter primes consumers for decisions about healthy foods than the traditional generic messages of \"eat\\nbetter.\".\\nWe installed our system in an actual grocery aisle of a real store to see how easy and quick subjects\\nreported finding healthy food products and avoiding unhealthy ones using our application with AR tagging.\\nIn addition, we have tested the functionality and performance of our application based on the data that we\\nhave accumulated from 104 participants of our online demonstration/survey.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[Document(metadata={'source': 'data\\\\introduction_and_background.docx'}, page_content='Introduction And Background\\...')]\n",
    "\"\"\"\n",
    "docx_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\ingredient_substituent.html'}, page_content=\"Ingredient Substitutions and FoodKG\\n\\nA comprehensive approach to ingredient substitutions and healthy alternatives using FoodKG and DIISH heuristic.\\n\\nIngredient Substitutions\\n\\nSource [10] has examined all possible identification directions and the suggestion of ingredient alternatives. FoodKG is described as a knowledge graph that allows ranking the most plausible alternatives for explicit semantic information, as well as the implicit semantics captured by word embeddings, leading users toward healthy choices based on dietary requirements and preferences.\\n\\nFoodKG: A Food Knowledge Graph\\n\\nFoodKG is a knowledge graph of recipes and their ingredients, sourced from various references:\\n\\nFood Category: FoodKG utilizes knowledge from the FoodOn ontology to classify ingredients.\\n\\nNutritional Content: FoodKG associates ingredients with USDA data, offering detailed nutritional information (calories, macronutrients, and micronutrients).\\n\\nRecipes: FoodKG includes various recipes, enabling analysis of ingredient occurrences and recipe contexts.\\n\\nFigure 4 and reference [15] show how FoodKG links ingredient information with FoodOn ontology and USDA nutritional data:\\n\\nNaming Target Ingredients and Healthy Alternatives\\n\\nFoodKG helps identify ingredients to replace based on dietary restrictions. The system considers:\\n\\nIngredient Type Restrictions: Based on FoodOn’s class hierarchy, it automatically infers proscribed ingredients (e.g., meat for vegetarians).\\n\\nNutritional Content Constraints: The app computes the nutritional content using USDA data to highlight ingredients contributing to restricted nutrients.\\n\\nRanking Possible Substitutions: The DIISH Heuristic\\n\\nSource [8] introduces the Diet-Improvement Ingredient Substitutability Heuristic (DIISH), which combines explicit and implicit semantics using word embeddings like Word2Vec and spaCy. DIISH uses four scoring metrics:\\n\\nCo-occurrence Similarity: Measures the co-occurrence of ingredients in recipes.\\n\\nRecipe Context Similarity: Captures the similarity in recipe contexts between the target ingredient and potential substitutes using PPMI.\\n\\nThese scores are combined into a ranking formula that suggests meaningful ingredient substitutes, excluding ingredients that are superclasses or subclasses of the target.\\n\\nEvaluation and Sample Results\\n\\nDIISH’s effectiveness was tested using three datasets, demonstrating superior performance compared to baselines. The following table shows some substitution examples:\\n\\nTarget Ingredient Ground-Truth Substitutes DIISH's Top 5 Ranked Substitutes Arugula Watercress, Belgian endive, Radicchio, Escarole Watercress, Frisee, Radicchio, Romaine lettuce, Butter lettuce Lard Vegetable oil, Shortening, Margarine, Bacon fat Vegetable shortening, Shortening, Margarine, Bacon fat, Butter\\n\\nExample Use Case: Diabetic Patient\\n\\nSource [15] demonstrates the application of DIISH for a diabetic patient seeking to reduce carbohydrate intake. The system suggests healthier substitutes for potatoes:\\n\\nRanked Substitutes Carbohydrates per 100g Turnip 6.4g Squash 6.9g Cauliflower 5.0g Butternut squash 11.7g Zucchini 3.1g\\n\\nCustom Databases and Local Food Products\\n\\nIn addition to FoodKG, custom databases tailored for local food products have been developed, such as a mobile app that combines barcode scanning with OCR technology to identify food ingredients and provide health advice. This app supplements information from open-source databases like Open Food Facts [17].\\n\\nReferences:\\n\\n[10] Source on ingredient identification and suggestions.\\n\\n[15] FoodKG and DIISH heuristic references.\\n\\n[17] Open Food Facts for local food data.\")]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[Document(metadata={'source': 'data\\\\ingredient_substituent.html'}, page_content=\"Ingredient Substitutions and FoodKG\\....\")]\n",
    "\"\"\"\n",
    "html_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pdf_docs + txt_docs + md_docs + docx_docs + html_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(pdf_docs) = 37\n",
      "len(txt_docs) = 1\n",
      "len(md_docs) = 1\n",
      "len(docx_docs) = 1\n",
      "len(html_docs) = 1\n",
      "len(docs) = 41\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(pdf_docs) = }\")\n",
    "print(f\"{len(txt_docs) = }\")\n",
    "print(f\"{len(md_docs) = }\")\n",
    "print(f\"{len(docx_docs) = }\")\n",
    "print(f\"{len(html_docs) = }\")\n",
    "print(f\"{len(docs) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(texts) = 172\n"
     ]
    }
   ],
   "source": [
    "from numpy import add\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "\n",
    "texts = text_splitter.split_documents(docs)\n",
    "print(f\"{len(texts) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 0, 'start_index': 0}, page_content=\"AI Based AR Application for Food Ingredients\\nAnalysis: A Systematic Review\\nPrathamesh K. Sable Mr. \\n \\n, \\nParth C. Desai Mr. \\n \\n, \\nShivam B. Thorat Mr. \\n \\n, \\nKrunal A. Changan Mr. \\n \\n,\\nShobha S. Raskar Mrs. \\n1.\\n Computer Engineering, Modern Education Society's Wadia College of Engineering, Pune, Pune, IND\\nCorresponding authors: \\nPrathamesh K. Sable Mr., \\nprathameshks2003@gmail.com, \\nParth C. Desai Mr.,\\nparth.desai0910@gmail.com, \\nShivam B. Thorat Mr., \\nshivamthorat1077@gmail.com, \\nKrunal A. Changan Mr.,\\nkrunalchangan@gmail.com, \\nShobha S. Raskar Mrs., \\nshobha.raskar@mescoepune.org\\nAbstract\\nGroceries shopping forms the everyday need of most the person. However, there is a large variety of almost\\nsimilar products that can be found lined up at the shelf in the supermarket. Customers spend the most time\\nin the supermarket while reading the ingredient list on the nutrition facts label to select the best product they\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 0, 'start_index': 924}, page_content='want. Despite being time-consuming, the greatest challenge that a shopper faces is being able to limit and\\nsearch for products that do not contain any allergy ingredients at all. Therefore, it is proposed that a grocery\\nsmart shopping application supported with AR technology in ﬁltering ingredients be provided. Therefore, the\\nproposed application has the capability to help the user ﬁlter and customize the ingredient that a user wants.\\nIn this development, AR technology is utilized in this project in the form of marker-based AR.\\nCategories:\\n AI applications, Augmented and Virtual Reality (AR/VR), Health Informatics\\nKeywords:\\n ingredients analysis, food label reading, augmented reality (ar), packed food alternatives, harmful\\ncompounds in packed food\\nIntroduction And Background\\nINTRODUCTION\\nIt has been richly noted that information technology could catalyze an important set of beneﬁts in the'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 0, 'start_index': 1826}, page_content='healthcare area which would include improving the quality and reducing the cost of healthcare. The\\nemergence of sensor-rich powerful smart phones to provide a rich set of user contextual information in real\\ntime made it feasible to provide eﬀective and aﬀordable healthcare to nearly everyone via smartphones.\\nMore speciﬁcally, well-designed mobile phone applications can empower individuals to proactively embrace\\nhealth and wellness. No longer is the health care system made of a reactive system or placed sitting back\\nwaiting for medical attention to surface via an ER visit. What once belonged to the clinic is now patient-\\ncentered care. What once focused on the disease agenda is now wellness in health care.\\nBased on the sheer number of excellent justiﬁcations for applying smartphones, cloud computing, mobile\\naugmented reality and other information technologies to improve health and well-being in society, this paper'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 0, 'start_index': 2753}, page_content=\"examines the interactive, creative, and user-friendly health mobile applications. Previous studies have\\nclearly established a correlation between low levels of nutritional intake and the rising prevalence of\\nunhealthy conditions such as obesity and lifestyle diseases such as heart disease and diabetes. A lack of\\nhealthy food consumption coupled with physical inactivity is two key causes of an epidemic of overweight\\npersons and cases of obesity in the United States. The betterment of a person's diet begins with the\\nbetterment of the nutritional quality of food he or she chooses. This makes it nearly impossible for the\\naverage consumer to make better choices when a food supply contains tens of thousands of processed and\\npackaged foods with diﬀerent messages on bags, boxes, bottles, jars, and cans. Consumers report they\\nknow what is healthy and what isn't, but say they are confused over how to implement general nutritional\\nadvice.\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 0, 'start_index': 3687}, page_content='advice.\\nThe application of technology in diet management has been perceived as a useful tool and resource in\\nhelping to reduce poor health conditions and foster good well-being generally among people. Mobile\\naugmented reality in supermarkets is one of the proposed solutions to this very pressing problem of\\nenriching the quality of nutrition in food choices while shopping at the point-of-sale. One of the more\\ninteresting emerging technologies AR exempliﬁes, in very simple words, simply oﬀers rich visual interaction\\nwith the real world by overlaying or augmenting the elements the camera view contains with useful\\ninformation with relevance to the objects appearing in the video screen of the camera. With an AR-based\\nsmartphone application, the user now experiences a direct interactive or context-rich experience. Actually, it\\nis just recently that AR gained much mindshare as an exciting new technology for the mobile smartphone.\\n[1]'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 0, 'start_index': 4624}, page_content='[1]\\nSome examples of such applications are an augmented reality range ﬁnder for golf lovers, Cape GPS\\nRangeﬁnder; AR application for color-blind people; Google Sky Map, that is an AR application for amateur\\n1\\n1\\n1\\n1\\n1\\n Cureus Journal of Computer Science  \\nOpen Access Review\\nArticle\\nHow to cite this article'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 1, 'start_index': 0}, page_content='astronomers; Word Lens, that translates a foreign language captured by the mobile camera and overlays\\nthe result on top of the text; and many more. As the user continues walking down an aisle to get an item, its\\nAR tag grows in size. When the tags of the thing are clicked, it provides nutrition information about that\\nproduct. Tags are colored. Therefore, for example, green would be nutritionally preferable items-low calorie\\nand gluten-free. Red would be used to mark bad products to avoid. For example, those that have a high\\ncholesterol level or peanut contents. Additionally, the consumers can upload health proﬁles that might have\\nan inﬂuence on their purchasing of food products such as weight watch, heart condition, and food allergies,\\netc. We observe that the product to be recommended will diﬀer because the user has provided an input\\nhealth condition/cue. To our knowledge system, we strongly believe that we are the ﬁrst ones that introduce'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 1, 'start_index': 955}, page_content='AR tagging with pedometric-based localization along with back-end health-based grocery recommendation\\nat point of purchase.\\nPoint-of-purchase nutrition information probably would have greater impacts on dietary quality because it\\nbetter primes consumers for decisions about healthy foods than the traditional generic messages of \"eat\\nbetter.\".\\nWe installed our system in an actual grocery aisle of a real store to see how easy and quick subjects\\nreported ﬁnding healthy food products and avoiding unhealthy ones using our application with AR tagging.\\nIn addition, we have tested the functionality and performance of our application based on the data that we\\nhave accumulated from 104 participants of our online demonstration/survey.\\nReview\\nThere are some works regarding shopping assistant that has done by other researchers. However, there are\\nstill many challenges and limitation exist in their works. Hence, several relevant methods regarding'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 1, 'start_index': 1901}, page_content='shopping in AR will be reviewed including the limitations and some proposed solutions.\\nA. AR Frameworks in the Food Industry\\nThere are numerous sources that detail multiple AR frameworks, like Vuforia and ARCore and MAXST, and\\nusage of the tool while going for grocery shopping in such an industry.\\nSource \\n[1]\\n \\ncompares the functionality of the three frameworks for creation of a mobile AR grocery shopping\\napp. Here, it scans a product and gives information and shows them on the smartphone screen. This paper\\nis a performance evaluation for target recognition and tracking in the real world, wherein a grocery store\\nwas selected to run experiments. The development teams checked the proposed architectures by using\\nthree food packaging types: box-type, cup-type, and pouch-type. AR content is a simple 2D image, name of\\nthe product 4. Fig. \\n1\\n. Some of the target image features of these packages from the source.\\nFIGURE\\n 1: Type Of Diﬀerent packaging'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 1, 'start_index': 2819}, page_content='FIGURE\\n 1: Type Of Diﬀerent packaging\\nThe conclusion is that, on the whole, Vuforia performed comparatively better than these two, which are\\nMAXST and ARCore. MAXST worked well in terms of detecting a target from afar, but Vuforia has more\\nrobustness with regard to occlusion conditions. Put diﬀerently, if the target is partially hidden, then Vuforia\\nwould perform better in that context than MAXST. On the other hand, the ARCore was the lowest of the\\nthree and could only capture one target at a go\\n \\n[1]\\n.\\nOther scope of applications of AR in the food industry is discussed along with sharing the vision of potential\\n Cureus Journal of Computer Science\\n2\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 2, 'start_index': 0}, page_content='roles for AR as a part of progression in the advanced concept of Industry 4.0. The author indicates that AR\\nis seen as a digital facility connecting various entities involved in the food supply chain, and all the merits\\ncan vary from enhanced employee safety and training to developing products up to marketing. Although\\nthis resource is not very descriptive on frameworks for AR, it does give a good starting point in\\nunderstanding the continually growing role that AR is starting to play within the food industry.\\nAccording to sources, the AR frameworks can revolutionize the food industry. First, they will create\\napplications, which can provide information regarding the products of food so that good decisions and\\nexperiences in shopping are made. AR can be integrated into almost all aspects of the food supply chain for\\neﬃciency, safety, and innovation.\\n \\nB. Target Recognition and Tracking in AR'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 2, 'start_index': 827}, page_content='eﬃciency, safety, and innovation.\\n \\nB. Target Recognition and Tracking in AR\\nThe AR enriches the grocery shop consumer experience by projecting virtual content including nutritional\\ninformation, recommendations, and interactive displays onto real-world objects, Using OCR tools and AR\\nframeworks like ARCore and ARFusion. It, therefore, has to exploit the most advanced beneﬁts of target\\nrecognition and tracking capabilities in overlaying adequate content. It is required to detect and track the\\ntarget objects under dynamically changing conditions such as grocery stores whose lighting conditions,\\nplacements of products or movements of users can aﬀect its performance\\n \\n[2, 3, 4]\\n.\\nThe functionalities and performance of target recognition and tracking capabilities are diﬀerent in every AR\\nframework. Some very popular ones are Vuforia, ARCore, and MAXST \\n[2]\\n. It proposes various techniques\\nlike marker-based tracking, image recognition, etc. for the identiﬁcation of target objects.'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 2, 'start_index': 1724}, page_content='like marker-based tracking, image recognition, etc. for the identiﬁcation of target objects.\\nMarker-based tracking places AR markers on products or on the shelves, for tracking \\n[2, 3]\\n. These markers\\nact as references from which the AR system can perceive with ease and accuracy the position and\\norientation of an object in space. Identiﬁcation of a product is performed via image recognition techniques,\\nbased on analysis of visual features on the packaging of a product \\n[3]\\n. Current AR applications are engaged\\nin the practice of recognizing a vast range of product features with some advanced computer vision\\nalgorithms.\\nThe type of AR framework selected determines the performance in recognizing and tracking the target. A\\ncomparative analysis between Vuforia, ARCore, and MAXST revealed each to have its strengths and\\nweaknesses in the process \\n[2]\\n. Strength of MAXST was maximum recognizable distance as it could identify'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 2, 'start_index': 2577}, page_content='[2]\\n. Strength of MAXST was maximum recognizable distance as it could identify\\ntargets from a higher distance. Strength of Vuforia is maximum recognizable occlusion since it can\\nrecognize occluded targets as well when partially covered by some other objects. Vuforia was also superior\\nin terms of the number of targets that it could simultaneously recognize and track. ARCore only recognized\\nand tracked one target at a time.\\nTarget recognition and tracking accuracy with reliability will thus validate that the AR experience at grocery\\nstores continues being seamless and informative to the users. Techniques are thus being researched into\\nways that will make these systems better, such as data caching and adaptive AR tag presentation \\n[2]\\n. These\\nought to be able enough to overcome dynamic grocery store environments in the presentation of enhanced\\nconsumer shopping experiences.\\nC. Related Work on Mobile AR Applications for Food-Related Tasks'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 2, 'start_index': 3430}, page_content='consumer shopping experiences.\\nC. Related Work on Mobile AR Applications for Food-Related Tasks\\nSources point out numerous cases of applications of mobile AR designed to support in diﬀerent procedures\\nrelated to food. In general, they create images of the real world using the camera of a smartphone, applying\\ndigital information, or data about the nutrient content, ingredients analysis, health-related information, etc.\\nOne of the key applications is \"ARFusion,\" which is about healthy grocery shopping. This application relies\\non a pedometric, image recognition, and a backend server to deliver recommendations based on a health\\nproﬁle deﬁned by the user.\\nFigure \\n2\\n demonstrated that nutrition is the leading qualitative characteristic of foods for consumers, which\\nled the developers to the nutrition-led approach.\\n[3]\\n Cureus Journal of Computer Science\\n3\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 3, 'start_index': 0}, page_content='FIGURE\\n 2: Use case of PHARA: a) user, b) desktop interface to create or\\nedit the user proﬁle, c) basket to place the food products d) PHARA\\nmobile app e) store shelf\\n \\nFor instance, there is \"PHARA\" that is a product-based AR solution that is supposed to aid consumers to\\nselect healthy grocery foods. The primary screen of the application, as displayed in Figure 5 of Reference ,\\nindicates one of its key functionalities making use of AR markers of products in the display of information\\nattached to them. This method, as expected, provides visual cues for scanning information for the user \\n[3]\\n.\\nAccording to source \\n[3]\\n, the iterative design process of PHARA starts from paper prototypes to a fully\\nfunctional mobile AR prototype. The system bases its architecture on a client-server architecture, whereby\\nthe visual components are rendered at the client end by mobile clients using frameworks like Unity and\\nVuforia \\n[5]\\n.'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 3, 'start_index': 915}, page_content='Vuforia \\n[5]\\n. \\nBesides the above two examples in particular, many other research studies test mobile AR applications for\\nfood preparation tasks along other lines:\\n•Ingredient Analysis: A research developed a mobile application that scans an ingredient list directly from\\nthe product labels using OCR. Such a step is quite beneﬁcial for users who have food allergy by warning\\nthem of the presence of allergens. Generally, how such a system works is depicted in ﬁgure \\n3\\n \\n[5]\\n. It mashes\\nbarcode scanning with OCR techniques to fetch ingredient information and oﬀer health advice. Preliminary\\nuser study results show that for concerned consumers of their diet, the app is found useful \\n[5,1]\\n.\\nFIGURE\\n 3: An overview of PHARA system.\\n• Customized Recommendations: A study in Source \\n[6]\\n has been released with comparative performance of\\nseveral AR frameworks to grocery shopping applications based on the AR. Target recognition and tracking,\\n Cureus Journal of Computer Science\\n4\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 4, 'start_index': 0}, page_content='a technical approach towards overlaying digital information over real-world objects, have mainly comprised\\nthis paper. This paper stresses the point of choosing a proper AR framework based on application needs \\n[6,\\n7]\\n. \\n• Nutritional Information: A recently published research work examines the impact of an application of a\\nfood scanner on consumer choice compared to FOP labels and no information at all. In the study, it is\\nalready found that the application actually enhanced the purchase intentions of healthy products, but it did\\nnot aﬀect the actual choices regarding the grocery shopping environment \\n[7]\\n. They further argue that\\nperhaps this is because the weakness of the application is due to the added complexity of a situation when\\none scans a barcode in a retail shop by the ease in calculation in FOP tags \\n[4]\\n. \\n• Food Industry Applications: Reference Source\\n \\n[4]\\n for applications in the food industry generally, based on'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 4, 'start_index': 880}, page_content='[4]\\n for applications in the food industry generally, based on\\ntransparency and improved procedures. It even provides a framework for the three-phase implementation of\\nAR in the food sector. Such studies demonstrate that mobile AR applications can actually change the eating\\nhabits of humans and the entire capability of consumers to make healthy and informed diet and health\\nchoices. \\nToday, it is indeed in the area of interface design and data analysis that computer vision research and\\ndevelopment are concentrated, leading to continuous stretches in the features of these applications-more\\nand more personalized, engaging, and eﬀective food-related AR experiences. \\nD. Food Ingredient Databases:\\nAccessible and comprehensive food ingredient databases are a benchmark for mobile applications meant to\\nenhance dietary choices and outcomes. It contains detailed data of food products, among which are the\\ningredients, nutritional values, and potential allergens. \\n[4]'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 4, 'start_index': 1787}, page_content=\"ingredients, nutritional values, and potential allergens. \\n[4]\\n One such example includes the open source\\ndatabase known as Open Food Facts, containing over 50,000 entries of food products present in 134\\ncountries. \\n[5]\\n \\nHowever, often, custom databases need to be created with regard to speciﬁc requirements so\\nthat local food products may be covered.\\n \\n[8]\\n \\nOne is PHARA, which uses a client-server architecture with a MongoDB database to implement\\nrecommendations of healthy foods. The database contains items as well as user proﬁles. It feeds this\\ninformation into the application's recommendation engine whereby consumers marked out healthier foods\\nthey liked and wanted by preference and need\\n[5]\\n.\\nAnother application is regarding ingredient analysis especially concerning food allergies. This is done using\\na barcode scanner and OCR by scanning the ingredients against a food and health database having known\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 4, 'start_index': 2706}, page_content=\"allergens. Ingredients scanned will alert the users on those materials that can cause allergic reactions. \\n[5]\\n \\nARFusion is the grocery shopping application enabled with AR based on a health-based model of nutrition,\\nand has personal and family proﬁles ﬁlled into it. It requires relating data from product database tracking\\ninformation of every product's ingredient, nutrient, and the location in the grocery, which information allows\\nthe application to make real-time personalized recommendations on healthy products.\\n \\n[9]\\n \\nMoreover, the substitution of ingredients is performed using knowledge graphs. One such system was\\ncreated based on a knowledge graph called FoodKG which interconnected the ingredients with the food\\nontology named FoodOn and even nutritional information by USDA. This system points out healthy\\nalternatives according to dietary restrictions. \\n[10]\\n \\nTherefore, there is a great need to establish such comprehensive food ingredient databases that would be\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 4, 'start_index': 3690}, page_content='accessible for consumers so that they might choose their foods wisely, where they would enjoy better habits\\nof consumption and general well-being. \\n[4]\\n \\nE. UI/UX in Food-Related Mobile Applications: A Balancing Act\\nBut of both, what shines through is the role that well-designed UIs and UXs play especially for the mobile\\napplications concerning food. Rather more salient considerations piling too much information on users or\\ntaking them through complicated navigation is more nuisance to engagement and eﬀectiveness resulting\\nfrom balancing clamor for quick and easy access of such applications. \\nOne of the ways through which complicated information can be made accessible is through visual, such as\\ncolor-coded tags and intuitive layouts. The result of the study was that the color-coded AR tags were very\\neasy for the users to distinguish between the healthy and unhealthy products. The developers of the'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 4, 'start_index': 4501}, page_content='easy for the users to distinguish between the healthy and unhealthy products. The developers of the\\nPHARA attempted to develop modular visual parts that would pass relevant information in a clear-cut\\n Cureus Journal of Computer Science\\n5\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 5, 'start_index': 0}, page_content='manner. Figure 8 of this source shows several layouts of PHARA in making food product information\\nunderstandable. \\n[3]\\n \\n \\nFor example, the design of a mobile application concerning the ingredient analysis is essential to make sure\\nit becomes user friendly, considering there are food allergic users who might at some point require\\nassistance. The interface of the application focused on simplicity in daily use. \\n[3]\\n \\nTherefore, developers have to face the speciﬁc functional-related issues pertaining to such applications. For\\nexample, food scanner applications require one to scan the barcodes of each article purchased in the\\nmarket. It is cumbersome and time-consuming in the process. These features, combined with overall\\ninformation regarding nutritional content usually available, pose a burdensome job for the user to go through\\nthe information and take the right decisions. \\n[3]\\n \\nOn the contrary, FOP labels present a much less complicated approach. FOP labeling acquires the real'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 5, 'start_index': 993}, page_content=\"simpliﬁed nutritional information on product packaging. This ease of access and processing becomes a\\ngood reason why FOP labels are more eﬀective in determining consumer choices compared to food scanner\\napps. \\n[11]\\n \\nAnother great UI/UX is restaurant AR menus. With restaurant AR, the wish of the customers can be\\nsatisﬁed with three-dimensional images of dishes and even whole lists of ingredients; the menu can be\\ninteractive. The value of the information should be conserved rather than speed up the generation of the\\ncontent. In order to get success, the entire AR experience has to be intuitive as well as informative. \\n[4]\\n \\nMore generally, the sources emphasize that the development of successful food-related mobile apps will\\nrequire special attention to UI/UX principles. Balancing 'complexity' of features with the need for a seamless\\nuser experience is key to user engagement and, in the end, the impact of the app toward changing users'\\nhealthy choices.\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 5, 'start_index': 1942}, page_content=\"healthy choices.\\nF. AR's Inﬂuence on Consumer Behaivour: Potential and Pitfalls \\nSources investigate the eﬀects of Augmented Reality on consumer behavior, from developing the shopping\\nexperience to more challenges entailed in increasing complexity and ease of use. Although AR brings some\\ninnovative ways of interaction with the consumer in order to provide information eﬀectiveness is lower than\\nthe other, much more common inﬂuences, such as FOP labels. \\nImproving Food Choices Using Augmented Reality \\nA number of studies demonstrate the potential of AR to encourage healthier food choices. A study \\n[9]\\nexplored the feasibility of an AR application which gives users personalized suggestions of healthy products\\nto purchase in supermarkets. The application identiﬁed shelf products and overlaid color-coded ﬂags, thus\\nallowing users to point out healthy foods quickly along with bad guys to avoid them. Another app\\n \\n[1]\\n aimed\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 5, 'start_index': 2863}, page_content='[1]\\n aimed\\nto guide consumers toward making healthier selections focusing on diet. It relied on the color-coded\\nclassiﬁcation between healthy and unhealthy foods.\\nSource \\n[11]\\n would propose an AR application, PHARA, to aid in grocery store food product choice decision-\\nmaking. The application of AR is applied to represent information about food products to a user. \\nAnother study\\n \\n[1]\\n uses a mobile application-based AR, which provides information to consumers on products\\nusing AR and suggests healthy and similar products to the people. \\nFurthermore, researchers \\n[12]\\n conducted four studies to investigate the inﬂuence of a food scanner app\\n(Yuka) on consumer choice. They found that, whereas the app increased intentions to buy healthier\\nproducts in hypothetical situations, it had no impact on real behavior in the grocery store itself during an\\nexperimental supermarket setting. This gap between intentions and actual choices also points to the eﬀort'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 5, 'start_index': 3826}, page_content='which may be required to utilize it while shopping, thus constituting a barrier toward the eﬀectiveness of the\\napplication of the app. \\nAR vs Conventional Techniques \\nAll these sources point out that in almost all conditions, consumer behavior aﬀects AR interventions less\\ncompared to the traditional methods such as FOP labeling. A comparative study \\n[7]\\n where a head-to-head\\ncomparison of the app on the food scanner versus FOP labeling came out indicated that in all situations,\\nFOP labeling always outscored the application. \\n Cureus Journal of Computer Science\\n6\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 6, 'start_index': 0}, page_content=\"There are several reasons that can explain diﬀerences in performance. FOPs give consumers a look from\\nthe front of the package nutrition information directly accessible and easy to process. With AR applications,\\nespecially if they require scanning the barcode, their use will require more eﬀort from the user-which may\\ninterfere with the proper processing of the information or even reduce the making of an informed choice. \\nSource \\n[13]\\n concludes that food scanner apps are ineﬀective as substitutes to FOP labels since the\\ninformation is far more extensive and multiple scans are required for comparison of packaged products.\\nSuch multilevel processing of information might, in turn, sub-optimally aﬀect consumers' choices. \\nPotential Applications and Future Directions \\n \\nSources admit that, despite the problems in AR, it has uses and future directions. \\n• AR can be used to create interactive menus in restaurants so that customers can view three-dimensional\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 6, 'start_index': 965}, page_content='visualizations of the dishes and the lists of ingredients in detail\\n \\n[4]\\n. It may enhance customer engagement\\nand possibly your customer choice. \\n• AR can be embedded in food packaging so that consumers get a rich interaction experience \\n[4]\\n. Scanning\\nthe packaging shall unlock for users information regarding the nutritional data, the origin, and the process of\\nmanufacture along with virtual representations of the food. Such enhanced transparency and engagement\\nmight impact the purchasing decision. \\n•AR applications can be further developed to aid in new food product development \\n[4]\\n. Developers can\\neasily identify possible problems and then optimize a product for actual production by virtue of virtualization\\nof the product followed by its analysis in real environments or simulated environments. \\n• Further studies may be conducted to ascertain whether AR with other modes like FOP labels push\\nconsumers toward healthier diets \\n[14]'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 6, 'start_index': 1873}, page_content='consumers toward healthier diets \\n[14]\\n. Perhaps, in isolation, the strategy can do little but when merged, the\\nconstraints are crossed, and intervention becomes that much stronger. All levelled oﬀ, taken broadly, in a\\nrather convex shape to reveal the impact of AR on consumer behavior. Promises of AR about enhancing\\nshopping experiences and healthy choices seem alluringly good but simplifying complexity and ease of use\\nseem the biggest hurdles. Further research and development of optimal applications are required in their\\nrealization as regards their potential in shaping consumer behavior. \\n \\nG. Ingredient Substitutions:\\nSource \\n[10]\\n has examined all possible identiﬁcation directions and the suggestion of ingredient alternatives.\\nFoodKG is described in one of the references as a knowledge graph that allows ranking the most plausible\\nalternatives for explicit semantic information as well as the implicit semantics captured by word embeddings'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 6, 'start_index': 2829}, page_content='that lead the users toward healthy choices along with their dietary requirements and preferences.\\nFoodKG: A Food Knowledge Graph\\nFoodKG is a knowledge graph of recipes and their ingredients. There are thousands of sources that feed\\nthis knowledge graph.\\n• Food Category: FoodKG utilizes the knowledge from an ontology on food named FoodOn to classify the\\ningredients.\\n•Nutritional Content: FoodKG associates the ingredients with data from the USDA, thus yielding in-depth\\nnutritional content about calories, macronutrients, and micronutrients.\\n• Recipes: FoodKG contains various recipes so that the ingredient conccurrences as well as recipe contexts\\ncould be analyzed.\\nFigure \\n4\\n and reference \\n[15]\\n shows how FoodKG really connects ingredient information with FoodOn ontology\\nand even USDA nutritional data:\\n Cureus Journal of Computer Science\\n7\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 7, 'start_index': 0}, page_content='FIGURE\\n 4: Example of linked ingredient information in FoodKG for the\\ningredient “Unsalted Butter” to the matching class in FoodOn’s\\nontology and the USDA’s nutritional information.\\nNaming Target Ingredients and Healthy Alternatives\\n• It identiﬁes the ingredient to be replaced, basis speciﬁc dietary restrictions that can either be ingredient-\\nspeciﬁc or carry some speciﬁc nutritional content.\\n• Ingredient type restrictions: By the class hierarchy in FoodOn, the system can infer automatically the\\ningredients of proscribed types-for example, meat for vegetarians.\\n• Nutritional Content Constraints: Based on the user-deﬁned dietary goals such as carbs, the app computes\\nnutritional content values of all the ingredients using USDA data and catches on which ingredients are the\\nmajor contributors to restricted nutritional content.\\nRanking Possible Substitutions: the DIISH Heuristic\\n• Source\\n \\n[8]\\n then devises the Diet-Improvement Ingredient Substitutability Heuristic: explicit semantics'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 7, 'start_index': 898}, page_content=\"[8]\\n then devises the Diet-Improvement Ingredient Substitutability Heuristic: explicit semantics\\nmakes use of knowledge learnt from FoodKG while using implicit semantics predominantly through word\\nembeddings. It makes use of four scoring metrics\\n• It employs two word embedding models namely, Word2Vec, and spaCy for the embedding of latent\\nsemantic similarities between the names of the ingredients.\\n• Co-occurrence Similarity: It measures the co-occurrence similarity of ingredients which often co-occurs\\nwith the target ingredient in recipes, generalized by FoodOn's class hierarchy.\\n• Recipe Context Similarity: Based on the Positive Pointwise Mutual Information (PPMI) metric, this score\\ncaptures the similarity in recipe contexts between the target ingredient and potential substitutes, again\\nutilizing FoodOn links for generalization.\\nThese four scores DIISH combines into an ultimate ranking of possible substitutes through a weighted\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 7, 'start_index': 1841}, page_content='formula. The system also removes any substitutes that are either a super class or subclass of the target\\ningredient for more meaningful suggestions.\\nEvaluation and Samples\\nSource \\n[16]\\n tested the eﬀectiveness of DIISH on three ingredient substitution datasets constructed from\\ndiverse online sources and user reviews. Results report that DIISH performs better than baselines and thus\\npoint out the value added by the combination of explicit and implicit semantics for ranking ingredient\\nsubstitutions.\\n Cureus Journal of Computer Science\\n8\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 8, 'start_index': 0}, page_content=\"As presented in Table \\n1\\n, the DIISH substitutions made have some examples which show promise toward\\nproducing acceptable analogues:\\nTarget ingredient\\nGround-truth substitutes\\nDIISH's top 5 ranked substitutes\\nArugula\\nWatercress \\nBelgian endive \\nRadicchio \\nEscarole\\nWatercress \\nFrisee \\nRadicchio \\nRomain lettuce \\nButter lettuce\\nLard\\nVegetable oil \\nShortening \\nMargarine \\nBacon fat \\nButter\\nVegetable shortening \\nShortening \\nMargarine \\nBacon fat \\nButter\\nTABLE\\n 1: Examples of ground-truth substitutions compared to substitute options ranked by our\\napproach.\\nSource \\n[15]\\n also demonstrates DIISH's practical application through a hypothetical use case involving a\\ndiabetic patient aiming to reduce carbohydrate intake. The system identiﬁes potatoes as the primary\\ncontributor to carbohydrates in a chosen recipe and suggests healthier substitutes with lower carbohydrate\\ncontent. Table \\n2\\n presents the top ﬁve ranked substitutes:\\nTarget ingredient: potatoes\\nRanked substitutes\\nCarbohydrates per 100 g\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 8, 'start_index': 928}, page_content='Target ingredient: potatoes\\nRanked substitutes\\nCarbohydrates per 100 g\\nI. Turnip\\n6.4 g\\n2. Squash\\n6.9 g\\n3. Cauliflower\\n5.0 g\\n4. Butternut squash\\n11.7 g\\n5. Zucchini\\n3.1 g\\nTABLE\\n 2: Top ﬁve potato substitutions containing fewer carbohydrates than potatoes.\\nCustom Databases and Local Food Products\\nWhile FoodKG provides a comprehensive knowledge graph for food, the sources also discuss the\\ndevelopment of custom databases to address speciﬁc needs, such as local food products. For example, the\\ndevelopment of a mobile application that combines barcode scanning with OCR technology to identify food\\ningredients and provide health advice. To support this application, the developers created a custom\\ndatabase tailored for local food products, supplementing information from open-source databases like Open\\nFood Facts.\\n[17]\\nConclusions\\nThe integration of Artiﬁcial Intelligence (AI) with Augmented Reality (AR) to analyze content within food'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 8, 'start_index': 1865}, page_content='ingredients is one of the promising developments in digital management of health and nutrition.\\nApplications, technologies, as well as methodologies, have been tested to further an understanding on the\\ncontent in food in real-time and interactive manners. The potential of AI-based applications used in\\ncombination with computer vision, natural language processing, and machine learning has opened up\\nconsiderable avenues for not only detecting food ingredients but also estimating nutritional values and\\npotentially alerting users to possible allergens or dietary concerns.\\nThe biggest advantages that these applications oﬀer are on-the-spot information through visual overlays-an\\nintuitive, interactive experience for a user. This extends beyond the ability to allow the owner to take control\\nof choices made on which foods he or she should consume. It enhances the understanding of nutrient\\ncomposition in what is being consumed and what allergens may be included. This would greatly assist'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 8, 'start_index': 2759}, page_content='composition in what is being consumed and what allergens may be included. This would greatly assist\\npeople with special dietary requirements-those aﬄicted by diabetes, celiac disease, and other forms of food\\nallergies, where mobile applications can oﬀer that extra dimension of safety and ease regarding meal\\nplanning and consumption of food.\\nBut still, several challenges exist in creating highly accurate and reliable AI models for the identiﬁcation of\\n Cureus Journal of Computer Science\\n9\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 9, 'start_index': 0}, page_content='ingredients. Variability in food presentation, lighting, and packaging could inﬂuence recognition accuracy-one\\nof the signiﬁcant technical challenges. The other important aspect is creating large, reliable databases of\\nfood ingredients and their corresponding nutritional values to use in comprehensive analysis; it is a key\\nfactor for enhancing the performance of the application. Other challenges are ethical in nature and concern\\nprivacy and data security-in particular, as applications use personal dietary information in order to provide\\nspeciﬁc recommendations to users.\\nThere is a huge amount of need for future research studies in terms of directions toward strengthening the\\nalgorithms of AI in recognizing various food items under multicultural and regional settings. Better models of\\nmachine learning, which could accommodate customer preferences and dietary needs, would yield a better\\npersonalized and accurate application. Further advances in AR technology through better wearables and'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 9, 'start_index': 1000}, page_content=\"cellular devices will only contribute toward an enhanced user experience in the application of more realistic\\nand context-aware visual overlays.\\nThey are still at the nascent stages of AI-based AR applications for food ingredient analysis and have a\\ntremendous potential to transform how people interact with their food towards healthier, safer eating habits.\\nIf constant research and development can be carried out, then such tools may even prove to be\\nindispensable in personal nutrition management. Such cooperation will be indispensable for the complete\\nrealization of this ﬁeld's full potential, and AI developers, food scientists, nutritionists, and data privacy\\nexperts will have to collaborate intensively on overcoming technical, ethical, and practical hurdles.\\nAppendices\\nCHALLENGES \\n• Real World Performance Limitations. Grocery stores oﬀer a very challenging real world in which AR\\nframeworks operate, including product density, shelf guardrails and lighting conditions. These may limit\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 9, 'start_index': 1999}, page_content=\"recognition distance; therefore, the possibility of distinguishing unique products at greater distances is\\nreduced and may also make it diﬃcult to recognize multiple instances of product simultaneously. \\n• Misidentiﬁcation and Display Issues: Misidentiﬁcation appears to occur often with AR systems due to\\nsimilar appearances in packaging. Thus, displays are incorrect information. Again, when the consumer\\ndisplay AR information within cluttered shop environments, overlapping or obscured views may prevent the\\nuser from seeing and picking up products correctly. \\n• Intentions do not correlate with behavior: Food scanner apps may impact intentions to make healthier\\nchoices, but these intentions often don't continue into actual purchasing behavior. Scanning every product is\\ntedious and time-consuming, discouraging consistent use and, therefore limiting the overall impact of the\\napp. \\n• Data Gaps in Ingredient Substitution Systems: Besides ensuring adequate data about ingredients,\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 9, 'start_index': 2889}, page_content=\"• Data Gaps in Ingredient Substitution Systems: Besides ensuring adequate data about ingredients,\\ndeveloping robust systems of substitution requires complete ingredient information. This includes ingredients\\nspeciﬁc to regional or cultural environments. Where the available data is scarce and exact nutritional\\ncomputation cannot be correctly surmised, the system cannot adequately determine the ingredient\\nsubstitution to be done. \\n• Customization vs. Guidance. Ingredient substitution systems balance such user ﬂexibility with eﬀective\\nguidance. When customization is desired so that the system can consider the needs of dietary preferences,\\ntoo much freedom may dilute the system's capability in guiding a healthy choice. Too many choices are also\\noverwhelming for users and may decrease the likelihood of selecting the best alternative. \\n• Engagement and Usability: The main challenge in developing AR-based food scanners and ingredient\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 9, 'start_index': 3731}, page_content=\"• Engagement and Usability: The main challenge in developing AR-based food scanners and ingredient\\nsubstitution systems is very poor retention of users' engagement. A complicated interface, slow responses,\\nor the feeling that the scanning and substitution processes are too laborious forces the usage to decline\\nover time. Simplify interaction with relevant guidance so people stay on the system. \\n \\nFUTURE SCOPE \\n• Advancing AR Technology: Improvement in better object recognition by AR in real-world use cases can be\\nhighly regarded. Algorithms, improved by overcoming lighting, occlusion, and product density issues, will\\nmake applications like food scanners much more accurate and usable. \\n• Simultaneous and Accurate Identiﬁcation: In this concern, much work is required in the arena of\\nsimultaneous identiﬁcation of products and individualized items with correct algorithms so that\\nmisidentiﬁcations can be reduced with overall enriched user experience at grocery stores.\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 9, 'start_index': 4619}, page_content='misidentiﬁcations can be reduced with overall enriched user experience at grocery stores. \\n Cureus Journal of Computer Science\\n10\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10, 'start_index': 0}, page_content=\"• AR content optimization: Improvement in the delivery of AR content through enhancements in adaptive\\nsystems so that sensitivity to the viewer's proximity and angle of view is greatly enhanced to ﬁlter the\\ncontext so that the amount of appearing content is user-friendly.  Using customization attributes that\\nincorporate recommendation and gamiﬁcation, and also personalizing the content to the person, will make\\nthe AR-based food application more interactive for users. \\n• Therefore, the drivers of this gap between healthy intentions and actual behavior of users, will therefore\\nlead to better tools for the facilitation of healthier choice. \\n• Expanding ingredient libraries: The further an ingredient database is expanded with local and cultural\\ningredients, the more ingredient-substitution systems will both accurately and more appropriately react to\\ndiverse diets. AI and Machine Learning: AI-based personalization and prediction upgrade the food apps'\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10, 'start_index': 961}, page_content=\"brains to give smart suggestions and perfect substitutes for ingredients. Advanced data structures, such as\\na knowledge graph, make this system even more accurate. \\n \\nDISCUSSION\\nAnalyzing the contents in nutritional content and detecting allergens is a dimension of food ingredient\\nanalysis integrating AI with AR, on the cutting edge of digital health advancements. Real-time, interactive\\nanalysis can be made through applications that combine AI image recognition and machine learning\\ncapabilities with AR's immersion in interface design, hence opening access to detailed information on the\\ningredients instantaneously. This has proved very useful for people with dietary restrictions, allergies, or\\nchronic conditions since it promotes safer and more informed food choices.\\nThere are, however several challenges and limitations that arise in such attempts. Ingredient recognition\\noften gets aﬀected by environmental conditions such as lighting, food appearance, and packaging that make\"),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10, 'start_index': 1950}, page_content='AI models less reliable for such a data. It also comprises the complexity of producing a comprehensive food\\ndatabase. It demands the extensive collaboration and resources to support accurate analysis by cross-\\ncultural and regional food items. An important limitation in AI-based AR applications is the collection of\\nsensitive data, which varies for each app to enable user-speciﬁc recommendations, raising data privacy\\nissues. Data privacy rules and regulation require to ensure the protection of user data and generate trust\\namong users.\\nA key aspect of it is user experience, in the sense of intuitive and easy use towards broad adoption. Simpler\\ninterfaces and smoother integration into daily life will improve usability, but further developments in wearable\\nAR devices could make ingredient analysis even more accessible and convenient.\\nOther potential research directions include optimizing the performance of AI models, scaling databases to'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10, 'start_index': 2898}, page_content='accommodate an even greater variety of global foods, and enhancing data privacy. There are also larger\\npopulation health implications, such as a possible decrease in diet-related diseases and increased dietary\\nawareness through the use of AI-based AR applications. AI-based AR for analyzing food ingredients is still\\ndeveloping but promises much opportunity for revolutionizing nutrition management, making this practice-\\nassisted decision-making valuable for leading healthier lifestyles and hopefully achieving better public health\\noutcomes.\\nAdditional Information\\nDisclosures\\nConﬂicts of interest:\\n In compliance with the ICMJE uniform disclosure form, all authors declare the\\nfollowing: \\nPayment/services info:\\n All authors have declared that no ﬁnancial support was received from\\nany organization for the submitted work. \\nFinancial relationships:\\n All authors have declared that they have\\nno ﬁnancial relationships at present or within the previous three years with any organizations that might'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 10, 'start_index': 3898}, page_content='have an interest in the submitted work. \\nOther relationships:\\n All authors have declared that there are no\\nother relationships or activities that could appear to have inﬂuenced the submitted work.\\nAcknowledgements\\nWe would like to express our sincere gratitude to our guide, Prof. (Mrs.) Shobha. S. Raskar, for their\\ninvaluable \\nsupport, guidance, and encouragement throughout the course of this project. Their expertise and\\ninsights \\nwere instrumental in shaping our understanding of ML and AR technologies. \\nAdditionally, we\\nextend our thanks to our colleagues and peers who provided constructive feedback and \\nsupport during this\\nendeavor.\\nReferences\\n1\\n. \\nJuhwan Lee, Sangwon Hwang, Jisun Lee, Seungwoo Kang: \\nComparative Performance Characterization of\\nMobile AR Frameworks in the Context of AR-Based Grocery Shopping Applications\\n. 2020, 10(4):1547.\\n Cureus Journal of Computer Science\\n11\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 11, 'start_index': 0}, page_content='2\\n. \\nWei Zhu, Charles B. Owen, Hairong Li, Joo-Hyun Lee: \\nPersonalized In-store E-Commerce with the\\nPromoPad: an Augmented Reality Shopping Assistant\\n. 2004,\\n3\\n. \\nFrancisco Gutiérrez, \\nNyi Nyi Htun, Katrien Verbert: \\nPHARA: an augmented reality grocery store assistant\\n.\\nThe 20th International Conference. 2018, \\n10.1145/3236112.3236161\\n4\\n. \\nSandeep Jagtapa, Prateek Saxenab, Konstantinos Salonitis: \\nFood 4.0: Implementation of the Augmented\\nReality Systems in the Food Industry\\n. 2021, 104:1137-1142.\\n5\\n. \\nMan Wai WONG, Qing YE, Yuk Kai CHAN Kylar, Wai-Man Pang, and Kin Chung Kwan: \\nA Mobile Adviser of\\nHealthy Eating by Reading Ingredient Labels\\n. ResearchGate. 2016, \\n10.1007/978-3-319-58877-3_4\\n6\\n. \\nD.W.F. van Krevelen, R. Poelman: \\nA Survey of Augmented Reality Technologies, Applications and\\nLimitations\\n. International Journal of Virtual Reality. 2010, 9(2):1-20. \\n10.20870/IJVR.2010.9.2.2767\\n7\\n. \\nCarolina O.C. Werle, Caroline Gauthier, Amanda P. Yamim, Frederic Bally:'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 11, 'start_index': 903}, page_content='7\\n. \\nCarolina O.C. Werle, Caroline Gauthier, Amanda P. Yamim, Frederic Bally: \\nHow a food scanner app\\ninfluences healthy food choice\\n. 2024, 200:\\n10.1016/j.appet.2024.107571\\n8\\n. \\nPalakorn Achananuparp, Ingmar Weber: \\nExtracting Food Substitutes From Food Diary via Distributional\\nSimilarity\\n. 2016, \\n10.48550/arXiv.1607.08807\\n9\\n. \\nJUNHO AHN, JAMES WILLIAMSON, MIKE GARTRELL, RICHARD HAN, QIN LV, SHIVAKANT MISHRA:\\nSupporting Healthy Grocery Shopping via Mobile Augmented Reality\\n. 2015, 12:1-24. \\n10.1145/2808207\\n10\\n. \\nShirai Sola S. , Seneviratne Oshani , Gordon Minor E. , Chen Ching-Hua , McGuinness Deborah L:\\nIdentifying Ingredient Substitutions Using a Knowledge Graph of Food\\n. Frontiers in Artificial Intelligence.\\n2021, 3:\\n10.3389/frai.2020.621766\\n11\\n. \\nDavid Elsweiler, Morgan Harvey, Bernd Ludwig, Alan Said: \\nBringing the \"healthy\" into Food Recommenders\\n.\\nInternational Workshop on Decision Making and Recommender Systems. 2015,\\n12\\n.'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 11, 'start_index': 1770}, page_content='.\\nInternational Workshop on Decision Making and Recommender Systems. 2015,\\n12\\n. \\nRoland P. Abao, Cenie V. Malabanan, Adrian P. Galido: \\nDesign and Development of FoodGo: A Mobile\\nApplication using Situated Analytics to Augment Product Information\\n. Procedia Computer Science. 2018,\\n135:186-193. \\n10.1016/j.procs.2018.08.165\\n13\\n. \\nCampos S, Doxey J, Hammond D: \\nNutrition labels on pre-packaged foods: a systematic review\\n. 2011,\\n14(8):1496-506. \\n10.1017/S1368980010003290\\n14\\n. \\nPaweł Bryła: \\nWho Reads Food Labels? Selected Predictors of Consumer Interest in Front-of-Package and\\nBack-of-Package Labels during and after the Purchase\\n. 2020, 12(9):2605. \\n10.3390/nu12092605\\n15\\n. \\nSema Akkoyunlu, C. Manfredotti, A. Cornuéjols, N. Darcel, Fabien Delaere: \\nInvestigating Substitutability of\\nFood Items in Consumption Data\\n. 2017,\\n16\\n. \\nAmerican Diabetes Association: \\nFacilitating Behavior Change and Well-being to Improve Health Outcomes:\\nStandards of Medical Care in Diabetes—2022'),\n",
       " Document(metadata={'source': 'data\\\\review_paper.pdf', 'page': 11, 'start_index': 2707}, page_content='Standards of Medical Care in Diabetes—2022\\n. Diabetes Care 2022. American Diabetes Association, 2022.\\n45 (Supplement_1):\\n10.2337/dc22-Sint\\n17\\n. \\nRobert Adelmann: \\nMobile Phone Based Interaction with Everyday Products - On the Go\\n. The 2007\\nInternational Conference on Next Generation Mobile Applications, Services and Technologies (NGMAST\\n2007). 2007, 63-69. \\n10.1109/NGMAST.2007.4343402\\n Cureus Journal of Computer Science\\n12\\n of \\n12'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 0, 'start_index': 0}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/283661476\\nSupporting Healthy Grocery Shopping via Mobile Augmented\\nReality\\nArticle\\xa0\\xa0in \\xa0\\xa0ACM Transactions on Multimedia Computing, Communications and Applications · October 2015\\nDOI: 10.1145/2808207\\nCITATIONS\\n83\\nREADS\\n5,541\\n6 authors, including:\\nMike Gartrell\\nMicrosoft\\n37 PUBLICATIONS\\xa0\\xa0\\xa0911 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nRichard Han\\nUniversity of Colorado Boulder\\n168 PUBLICATIONS\\xa0\\xa0\\xa09,570 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nQin Lv\\nUniversity of Colorado Boulder\\n142 PUBLICATIONS\\xa0\\xa0\\xa07,434 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nShivakant Mishra\\nSri Ramswaroop Memorial College of Engineering and Manage…\\n170 PUBLICATIONS\\xa0\\xa0\\xa04,357 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Richard Han on 17 November 2015.\\nThe user has requested enhancement of the downloaded file.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 1, 'start_index': 0}, page_content='16\\nSupporting Healthy Grocery Shopping via Mobile Augmented Reality\\nJUNHO AHN, JAMES WILLIAMSON, MIKE GARTRELL, RICHARD HAN, QIN LV,\\nand SHIVAKANT MISHRA, University of Colorado Boulder\\nAugmented reality (AR) applications have recently become popular on modern smartphones. We explore\\nthe effectiveness of this mobile AR technology in the context of grocery shopping, in particular as a means\\nto assist shoppers in making healthier decisions as they decide which grocery products to buy. We construct\\nan AR-assisted mobile grocery-shopping application that makes real-time, customized recommendations\\nof healthy products to users and also highlights products to avoid for various types of health concerns,\\nsuch as allergies to milk or nut products, low-sodium or low-fat diets, and general caloric intake. We\\nhave implemented a prototype of this AR-assisted mobile grocery shopping application and evaluated its'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 1, 'start_index': 912}, page_content='effectiveness in grocery store aisles. Our application’s evaluation with typical grocery shoppers demonstrates\\nthat AR overlay tagging of products reduces the search time to ﬁnd healthy food items, and that coloring\\nthe tags helps to improve the user’s ability to quickly and easily identify recommended products, as well as\\nproducts to avoid. We have evaluated our application’s functionality by analyzing the data we collected from\\n15 in-person actual grocery-shopping subjects and 104 online application survey participants.\\nCCS Concepts: • Information systems → Information systems applications→ Mobile information processing\\nsystems\\nAdditional Key Words and Phrases: Augmented reality, mobile health, recommendation, grocery shopping,\\nnutrition\\nACM Reference Format:\\nJunho Ahn, James Williamson, Mike Gartrell, Richard Han, Qin Lv, and Shivakant Mishra. 2015. Supporting\\nhealthy grocery shopping via mobile augmented reality. ACM Trans. Multimedia Comput. Commun. Appl.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 1, 'start_index': 1788}, page_content='healthy grocery shopping via mobile augmented reality. ACM Trans. Multimedia Comput. Commun. Appl.\\n12, 1s, Article 16 (October 2015), 24 pages.\\nDOI: http://dx.doi.org/10.1145/2808207\\n1. INTRODUCTION\\nIt has amply been noted that information technology can help catalyze a number of\\nimportant beneﬁts in healthcare that include improving its quality and reducing its\\ncost [PCAST 2010]. With the emergence of sensor-rich, powerful smartphones that can\\nprovide a rich set of user contextual information in realtime, it has now become feasible\\nto provide effective and affordable healthcare to nearly everyone via smartphones. In\\nparticular, carefully designed smartphone applications have the potential to enable\\nindividuals to participate in their care, which transforms healthcare systems from\\nreactive to preventive, from clinic-centric to patient-centric, and from disease-centered\\nto wellness-centered.\\nThis article explores the use of smartphones, cloud computing, mobile augmented'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 1, 'start_index': 2692}, page_content='This article explores the use of smartphones, cloud computing, mobile augmented\\nreality and related information technology to help improve societal health and wellness.\\nEarlier research has shown a strong link between poor dietary choices and the increased\\nrisk of poor health conditions such as obesity as well as chronic diseases such as\\ncardiovascular disease and diabetes. Poor diet and physical inactivity are the two most\\nAuthors’ address: Department of Computer Science, University of Colorado, Boulder, CO 80309-0430, Cor-\\nrespondence email: mishras@cs.colorado.edu.\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted\\nwithout fee provided that copies are not made or distributed for proﬁt or commercial advantage and that\\ncopies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 1, 'start_index': 3594}, page_content='others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to\\npost on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request permissions\\nfrom permissions@acm.org.\\nc⃝ 2015 ACM 1551-6857/2015/10-ART16 $15.00\\nDOI: http://dx.doi.org/10.1145/2808207\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 2, 'start_index': 0}, page_content='16:2 J. Ahn et al.\\nFig. 1. A screenshot of our mobile application to assist in healthy grocery shopping. Augmented reality color\\ntags identify healthy and unhealthy products.\\nimportant factors contributing to an epidemic of overweight people and obesity in the\\nUnited States. Improving one’s diet begins by improving the nutritional quality of the\\nfood choices he/she makes. In a food supply including tens of thousands of processed and\\npackaged foods with diverse messaging on bags, boxes, bottles, jars and cans, making\\nmore nutritious choices is challenging at best for the average consumer [Katz et al.\\n2009]. Consumers claim to understand what is healthy and unhealthy, but acknowledge\\nconfusion over implementing general nutritional advice into practice [Lobstein and\\nDavies 2009]. Providing consumers with nutrition information at the point-of-purchase\\nhas the potential to improve consumer decision-making about healthy foods, and thus'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 2, 'start_index': 860}, page_content='has the potential to improve consumer decision-making about healthy foods, and thus\\nhave a greater impact on dietary quality than traditional generic messages of “eat\\nbetter”.\\nThe use of technology in managing diets has been heralded as an effective tool and\\nresource in helping to reduce the prevalence of poor health conditions and improve the\\ngeneral wellness of the public [Barton et al. 2006]. We propose to address the critical\\nproblem of improving the nutritional quality of the food choices individuals make by in-\\ntroducing mobile augmented reality (AR) at the point-of-purchase in grocery stores. AR\\nis one of the most exciting emerging technologies, and in simple terms provides rich\\nvisual interaction with the real world by augmenting or overlaying a camera’s view\\nwith computer-generated elements containing useful information relevant to the ob-\\njects shown in the camera’s video screen. With an AR-based smartphone application, a'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 2, 'start_index': 1721}, page_content='jects shown in the camera’s video screen. With an AR-based smartphone application, a\\nuser can enjoy an instantaneous interactive or context-rich experience. AR has recently\\nachieved signiﬁcant mindshare as an exciting new technology for mobile smartphones.\\nExamples include Golfscape GPS Rangeﬁnder, an augmented reality range ﬁnder for\\ngolf lovers [Golfscape 2014]; DanKam, an AR application for people suffering from\\ncolor-blindness [DanKam 2010]; Google Sky Map, an AR application for amateur as-\\ntronomers [SkyMap 2011]; Word Lens which translates a foreign language captured\\nby the mobile camera and overlays the result on top of the text [WordLens 2014]; and\\nmany more.\\nA prototype of our augmented reality mobile grocery shopping application is shown\\nin Figure 1. As the user pans and walks up and down a grocery store aisle, the AR\\ntags corresponding to highlighted products will change based on what products the'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 2, 'start_index': 2561}, page_content='tags corresponding to highlighted products will change based on what products the\\nuser is facing. As a user walks towards an item along the aisle, its corresponding\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 3, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:3\\nAR tag grows in size. The tags when clicked reveal nutritional information about the\\nproduct. The tags are also colored, for example, green to indicate products that are\\nnutritionally preferable (e.g., low-calorie, gluten-free), and red to indicate products to\\navoid (e.g., high cholesterol or peanut content). Further, shoppers can specify health\\nproﬁles which may impact their food purchase choices, such as weight control, heart\\ndisease, food allergies, etc. The recommended products shown via AR tags will then\\nchange depending on what health condition/concern is indicated by the user. We believe\\nour system is the ﬁrst to integrate augmented reality tagging and pedometry-based\\nlocalization with a back-end server to provide health-based grocery recommendations\\nat the point-of-purchase. We evaluated the effectiveness of our system in a real gro-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 3, 'start_index': 838}, page_content='at the point-of-purchase. We evaluated the effectiveness of our system in a real gro-\\ncery store aisle with 15 actual grocery shopping subjects to determine how easy and\\nfast the subjects reported it was to locate healthy food products and avoid unhealthy\\nones, using AR tagging with our application. We also evaluated our application’s func-\\ntionality and performance by analyzing data we collected from 104 online application\\ndemonstration/survey participants.\\n2. RELATED WORK\\nAugmented reality has been recently applied in the mobile health arena in a variety\\nof applications. For example, AR tags are overlaid in a home environment to pro-\\nvide instructions to the elderly for tasks like taking medication, cooking, washing,\\netc. [Herv´as et al. 2011]. TriggerHunter is an AR-based game that overlays tags on\\npotential asthma triggers in the local environment [Hong et al. 2010]. Neither project\\ncontains any evaluation. An AR-based game has been developed for mobile phones to'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 3, 'start_index': 1738}, page_content='contains any evaluation. An AR-based game has been developed for mobile phones to\\nhelp individuals overcome insect phobias by allowing patients to kill virtual insects\\noverlaid on the mobile screen [Botella et al. 2011]. A framework for several AR-based\\nQ&A games has been created to rehabilitate patients [Lin et al. 2011]. An AR-based\\nmobile game has been described that forces players to travel to various physical sites\\nto obtain AR-overlaid information, thus facilitating exercise [G¨org¨u et al. 2010].\\nSupermarkets are an excellent location to introduce informational [Ganapathy et al.\\n2011; Anderson et al. 2001; Wientt et al. 1997; Mhurchu et al. 2007] and dietary\\nbehavior [Kalnikaite et al. 2011; Mankoff et al. 2002] interventions because they are\\nthe place where most individuals in the United States make decisions and purchase\\ntheir food products. An example of an informational intervention is a system where'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 3, 'start_index': 2580}, page_content='their food products. An example of an informational intervention is a system where\\nparticipants take pictures of items, for example, chips, which are then matched in an\\nimage database to provide product information that is overlaid on the picture of the\\nproduct [Ganapathy et al. 2011]. This system requires shoppers to know exactly where\\nthe product is and still read the nutritional label on the packaging.\\nTo aid individuals locate the items they are looking for and provide a high level health\\ninformation about the products, visual guiding systems have been deployed in grocery\\nstores and supermarkets. To direct the individuals to the items of their interest, these\\nsystems work in a hierarchical way, for example, a large sign of a general category\\nsuch as “Produce” or “Dairy” visible from a distance followed by speciﬁc aisle signs\\nabout more speciﬁc item categories placed near the general category sign. Lately, these'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 3, 'start_index': 3421}, page_content='about more speciﬁc item categories placed near the general category sign. Lately, these\\nsystems have started providing general health related information such as “Le Bio”\\nor “Le Bonne” in Carrefour stores or “Organic” in Safeway stores. While these visible\\nguiding systems certainly help individuals in making healthy choices, a key limitation\\nis that they provide generic information and are not tailored for each individual based\\non his/her health condition and other factors. We compare the performance of our AR-\\nassisted mobile grocery app with a visual guiding system in a real grocery store in\\nSection 5.4.\\nOther informational interventions rely on shoppers stopping by a supermarket kiosk\\nto receive nutritional information [Anderson et al. 2001; Wientt et al. 1997] and coupons\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 4, 'start_index': 0}, page_content='16:4 J. Ahn et al.\\nto incentivize healthier choices [Mhurchu et al. 2007]. Although these systems did en-\\ncourage participants to purchase healthier food, marginalized populations were less\\nlikely to use the system. Ubiquitous grocery intervention systems are promising for\\ndietary behavior change because they are always with the shopper and can provide\\njust-in-time information about food items. For example, Mankoff et al. [2002] designed\\na system where shoppers could scan their receipts and receive information about the\\nnutrition of the items. This system provides shoppers the ability to reﬂect on the food\\nthat makes-up their diet after purchasing the foods. Other point-of-decision ubiquitous\\ncomputing applications for grocery shopping describe ways to use LEDs to inform the\\nuser either about nutrition through a small clip on stick [Mulrooney et al. 2006] or about\\nhow many miles the food traveled via a device clipped onto grocery carts [Kalnikaite'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 4, 'start_index': 877}, page_content='how many miles the food traveled via a device clipped onto grocery carts [Kalnikaite\\net al. 2011]. Similar to other work discussed, these systems require the user to know\\nthe location of the item and to select it to gain information about the item. Our ap-\\nplication makes real-time customized recommendations of healthy food items to get\\nand unhealthy (or harmful) food items to avoid, and AR-assisted color tags to facilitate\\nhealthy food purchase decisions.\\nRecommender systems have been an area of active research for decades and many\\ntechniques have been proposed (see Bobadilla et al. [2013] for a survey). A number\\nof food recommendation techniques have also been proposed recently, such as recipe\\nrecommendation [Freyne and Berkovsky 2010], context-aware food recommendation\\nat table [Oh et al. 2010], and food recommendation for people with diabetes [Phanich\\net al. 2010] or tourists with certain health concerns [Agapito et al. 2014]. In this work,'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 4, 'start_index': 1745}, page_content='et al. 2010] or tourists with certain health concerns [Agapito et al. 2014]. In this work,\\nwe aim to recommend/warn shoppers of grocery items in the current isle based on\\npersonal and family health proﬁles and grocery items’ nutritional information.\\nPedometry-based navigation using accelerometer data from mobile phones provides\\na convenient and low-cost way to monitor user progress up and down a grocery aisle\\nwithout requiring an extensive localization infrastructure. A variety of step estimation\\nalgorithms have been proposed [Fuchs et al. 2011; Ladstaetter et al. 2010; Beauregard\\n2007]. For our purpose of aisle navigation, we adapt a simple approach that achieves\\nsufﬁcient accuracy using personalized pedometry by estimating individual stride\\nlength [Ahn and Han 2011].\\n3. APPLICATION DESIGN OVERVIEW\\nOur goal is to build an indoor mobile augmented reality system for healthy grocery\\nshopping by leveraging the sensing and AR capabilities of smartphones and the knowl-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 4, 'start_index': 2639}, page_content='shopping by leveraging the sensing and AR capabilities of smartphones and the knowl-\\nedge of health rules in order to recommend appropriate products to purchase or identify\\nproducts to avoid. We seek to understand two basic questions.\\n—How much time does AR tagging of recommended products save a grocery shopper\\nwith a given health condition in comparison to the current approach of preparing a\\ngrocery shopping list?\\n—Does highlighting unhealthy products help the user to reduce the time it takes to\\nconﬁrm avoidance of items that would conﬂict with their health condition?\\n3.1. Design Requirements and Assumptions\\nOur system needs to be able to support navigation within a grocery store aisle. It needs\\nto provide AR-based tags that are geographically (i.e., shelf location along an aisle)\\nassociated with recommended products, or products to avoid. The recommendation\\nof healthy or unhealthy products needs to be determined in real time. The system'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 4, 'start_index': 3511}, page_content='of healthy or unhealthy products needs to be determined in real time. The system\\nshould measurably improve the shopping experience of the health-motivated shopper,\\nwhether measured by the reduction in time to ﬁnd their desired products, or by an\\nimproved ability to avoid unhealthy products. The system should be relatively easy to\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 5, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:5\\nFig. 2. The coordinate system we use for item locations in a grocery store aisle.\\nuse and learn. Also, the system should leverage existing low-cost sensors on most mobile\\ndevices, and not require a costly in-store infrastructure, such as an infrastructure for\\nlocalization.\\nBased on our discussions with local grocery stores, we ﬁnd that grocery stores have\\nan electronic product database, though not necessarily associated with location. Note\\nthat we do not require exact location of items on store shelves, but only approximate\\nsectional information along an aisle, quantized as shown in Figure 2. Given such a\\ncoordinate system, we can overlay tags of healthy/unhealthy items coarsely by section,\\nwhich should be sufﬁcient for the user to ﬁnd the items quickly. We demonstrate that\\nthis coarse quantization is sufﬁcient in our evaluation.\\nTo better understand users’ grocery shopping behavior with respect to their food'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 5, 'start_index': 912}, page_content='To better understand users’ grocery shopping behavior with respect to their food\\nproduct purchases, we conducted an online food-shopping demo and survey of 104\\nhuman subjects. This research was approved by Institutional Review Board (IRB) [Ahn\\net al. 2012]. The demo and survey consisted of three steps that participants were\\nrequired to complete.\\n(1) Participants ﬁnd four healthy products of their choice, that had low calorie and\\nno milk content, from among 60 picture-based grocery products displayed on the\\nwebsite.\\n(2) Participants view a 3-minute video demo to familiarize themselves with our shop-\\nping app.\\n(3) Participants provide feedback, including an evaluation of the brief picture-based\\nshopping experience, an evaluation of the video demo, and a detailed feedback\\non their personal grocery shopping behavior, focusing speciﬁcally on healthy food\\nshopping.\\nWe designed our online survey, using GoogleDocs’ online survey tool [GoogleDocs'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 5, 'start_index': 1774}, page_content='shopping.\\nWe designed our online survey, using GoogleDocs’ online survey tool [GoogleDocs\\n2014] and deployed it on Amazon’s public MechanicalTurk website [MechanicalTurk\\n2014].\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 6, 'start_index': 0}, page_content='16:6 J. Ahn et al.\\nFig. 3. Result of importance-rating for buying healthy food products (a) on a ﬁve-point scale, and (b) on a\\ntwo-point scale from healthy food shopper to less-interested shopper.\\nFig. 4. Comparison of the two groups’ pre-grocery-store visit healthy food searching behaviors.\\n3.2. Users’ Grocery Shopping Behavior\\n3.2.1. Healthy Food Shopping Behavior.We categorized participants into two groups:\\nthose who are more interested in buying healthy food products and those who are\\nless interested in buying such products. The reason to categorize people into these two\\ngroups is because people who are interested in buying healthy food products are likely\\nto be much more focused on healthy eating and ensuring that they can obtain healthy\\nfood products frequently and easily. Our goal in making this distinction between these\\ntwo groups was to see if their shopping behaviors were distinct from each other and'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 6, 'start_index': 840}, page_content='two groups was to see if their shopping behaviors were distinct from each other and\\nhow far apart ratings of their shopping behavior patterns would actually be. These re-\\nsults can therefore help us to better understand all users’ grocery shopping behaviors\\nand help us to further evaluate and improve the use of our application. We asked the\\nfollowing question: How important is it to you that you buy healthy products (e.g., low\\ncalorie, low sugar, organic, etc.) for yourself and/or your family when you go grocery\\nshopping?\\nWe categorized the two groups as follows: healthy food shoppers – those who provided\\nratings within the 4- to 5-point range (n = 76, 73%); and less interested shoppers – those\\nwho provided ratings in the 1- to 3-point range (n = 28, 27%) as shown in Figure 3(b). We\\ninvestigated three different food grocery shopping behaviors for members of these two\\ngroups: pre-grocery store visit searching behaviors for healthy food products; preferred'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 6, 'start_index': 1720}, page_content='groups: pre-grocery store visit searching behaviors for healthy food products; preferred\\nmethods searching for healthy products in a grocery store; and food quality factors\\nconsidered most important when choosing healthy products. Figures 4, 5, and 6 show\\na comparison between the two groups for these grocery shopping behaviors.\\nOur ﬁrst ﬁnding is that the healthy food shoppers spend almost twice as much\\ntime as the less-interested shoppers in using different search methods to search for\\nhealthy products prior to their grocery store visits. “Asking a doctor or friends” was\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 7, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:7\\nFig. 5. Comparison of the two groups’ in-grocery store healthy food searching behaviors (a) for ﬁnding\\nunknown location products and (b) for ﬁnding healthy food products.\\nFig. 6. Comparison of the two groups’ healthy food quality preferences in the picture-based demo.\\nthe most frequently noted method of preference for all users in gathering information\\non healthy food products. Our second ﬁnding is that when subjects need to ﬁnd a\\ngrocery product of interest, healthy food shoppers more frequently prefer using the\\naisle signs or asking grocery clerks than do the less-interested shoppers. Also a much\\nlarger proportion – three times as many healthy food shoppers as compared to the less-\\ninterested shoppers – preferred asking grocery clerks directly for help, when trying\\nto locate food products of interest. Additionally, when the subjects needed to locate a'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 7, 'start_index': 848}, page_content='to locate food products of interest. Additionally, when the subjects needed to locate a\\nhealthy food product, almost twice as many healthy food shoppers as the less-interested\\nshoppers, chose to browse the organic/natural food sections of the grocery store. Finally,\\nour third ﬁnding is that, while the order of importance for each of the food quality\\nfactors was the same for the two groups, “nutrition> ﬂavor > price > brand name >\\nvisual appeal”, a much larger percentage of healthy food shoppers considered nutrition,\\nbrand, and visual appearance as highly important food qualities in selecting a health\\nfood product than did the less-interested shoppers.\\n3.2.2. Nutrition-Based Multiple-Choice Data Collection.Our ﬁrst approach to investigating\\nthe kinds of healthy food content information our application should provide involved\\ncollecting online and in-person survey information from our initial project 25 partici-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 7, 'start_index': 1684}, page_content='collecting online and in-person survey information from our initial project 25 partici-\\npants as to the types of health conditions, diseases or food sensitivities, they or their\\nfamily members need to consider when shopping for food products. The 25 participants\\nand/or their family members had at least one health problem and 16% (n = 4) of them\\nhad more than two health problems. We asked the participants about their own health\\nconditions and their family members’ health needs, since we assumed that many shop-\\npers often shop not only for themselves, but for other family or household members as\\nwell. We found that 79% (n = 82) of the survey subjects usually buy grocery food prod-\\nucts for their family members when they go shopping. These two cases showed that our\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 8, 'start_index': 0}, page_content='16:8 J. Ahn et al.\\nmobile application would need to provide in-depth information on food products that\\nwere suitable for a large variety of multiple diseases and food sensitivities all at one\\ntime to the user, while she/he was shopping.\\nSince, there are just too many possible health conditions and combinations in the real\\nworld, providing correct recommendations for each and every possible heath condition\\nis impractical. So, we refocused our approach to a solely nutrition-based approach. In\\nthis way, regardless of the speciﬁc health condition or conditions of users, our applica-\\ntion would be set up to query users about the nutrition content of food products they\\nneed or wish to purchase. For instance, most users with a known speciﬁc health condi-\\ntion, have already been advised by their doctors as to which food products to avoid or\\nselect that will ameliorate their condition – for example, a person with diabetes would'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 8, 'start_index': 845}, page_content='select that will ameliorate their condition – for example, a person with diabetes would\\nalready have been advised to eat food products with low-sugar content. Later in our ap-\\nplication’s development, in surveying potential users of our application, we found this\\napproach to be corroborated by their feedback, when the largest percentages of both\\nthe healthy food shoppers (87%) and the less-interested shoppers (60%) indicated that\\nnutrition was the highest rated food quality factor of interest to them when purchasing\\ngrocery food products, as shown in Figure 6.\\n3.2.3. Preference of Aisle-Based Display.From the online survey data, we also found\\nthat potential users of our application prefer an aisle-based AR display of grocery\\nfood products on the smartphone over other types of displays. Participants were asked\\nto rate their preferences for three different AR displays of healthy/nutritional food\\nproducts recommended by the mobile application on the smartphone: all grocery store'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 8, 'start_index': 1752}, page_content='products recommended by the mobile application on the smartphone: all grocery store\\nproducts at once, one aisle’s products only, one section of an aisle’s products. Over\\nhalf (n = 59,57%) of the participants indicated preference for displaying recommended\\nfood products in one aisle only. Also, the online survey subjects indicated that they\\nhave frequently bought additional food products they were not originally planning\\nto buy, which were located near the product they were buying. This result indicates\\nthat another beneﬁt of an aisle-based AR application display is for users to be able to\\nevaluate more quickly nonplanned food purchases in the grocery store.\\n3.3. System Overview\\nOur system consists of an external image labeling service, a mobile cmponent, and a\\nremote cloud server component (see Figure 7). To determine the initial location of a user\\nin the grocery store, the mobile component sends a product snapshot to the cloud server'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 8, 'start_index': 2613}, page_content='in the grocery store, the mobile component sends a product snapshot to the cloud server\\ncomponent, which forwards that snapshot to an external image labeling service. This\\nexternal image labeling service returns the product identity to the cloud server, which\\nthen determines the current location (aisle) of the user by referring to an indoor layout\\nof the grocery store. After determining the identity of the aisle in the grocery store, the\\nmobile component estimates user motion, thus providing a position estimate within\\nthe aisle, as well as orientation. The user also inputs his/her health proﬁles on the\\nmobile client, for example, seeking some combination of low-calorie, low-sodium, low-\\nfat, lactose-free, nut-free, etc. items. This position estimate along with orientation and\\nhealth condition is then again communicated to the server, which consults the product\\nlocation database along with its health rules to come up with a recommendation of'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 8, 'start_index': 3486}, page_content='location database along with its health rules to come up with a recommendation of\\nproducts to buy or avoid. The server has access to the nutrition facts and ingredient\\nlists of products, and can thus apply health rules to decide whether products are healthy\\nor not for the given health condition(s). These highlighted items are then sent to the\\nmobile client, which renders the recommendation results on the screen via AR. In order\\nto achieve real-time performance, it is helpful for the mobile application to cache data\\nitems locally on the client, so as to avoid excessive network communication latency.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 9, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:9\\nFig. 7. System architecture.\\nIn order to meet the objectives of low-cost, low-infrastructure navigation within a\\ngrocery store aisle, we use three-axis accelerometer information obtained from a user’s\\nmobile phone to estimate the distance traveled by a walking user. We build one such\\npersonalized pedometry system into our application.\\nIn order to match the 3D perspective of a supermarket aisle and the intuition of the\\nuser about how far away a tagged item is located, the AR tags for items that are closer\\nto the user are rendered larger than the tags corresponding to more distant items. The\\nresult is that as a user navigates down an aisle, tags grow in size until they pass by\\nout of view as the user walks past the item, thus giving the user a 3D AR experience.\\nIn order to clearly differentiate between healthy and unhealthy products in the user'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 9, 'start_index': 840}, page_content='In order to clearly differentiate between healthy and unhealthy products in the user\\ninterface, we have used intuitively colored tags: green for good/healthy products; red\\nfor products to avoid. We measure the effectiveness of this approach in the evalua-\\ntion section. Additional mappings of colors to different categories of food were consid-\\nered, for example, vegetables, meats, dairy, fruits. We found that the latter approach\\nwas confusing, therefore we focus only on the color tagging of healthy/unhealthy food\\nproducts.\\n4. SYSTEM COMPONENTS\\n4.1. Image-Based Positioning\\nOur system requires accurate determination of the user’s location in an indoor envi-\\nronment. Locating the user in an indoor environment using the hardware available on\\na smartphone is a challenging problem. The Global Positioning System (GPS) cannot\\nbe used in indoor environments, since line-of-sight communication between GPS re-\\nceivers and satellites is not possible in an indoor environment. Radio frequency (RF)'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 9, 'start_index': 1751}, page_content='ceivers and satellites is not possible in an indoor environment. Radio frequency (RF)\\npositioning systems that use WiFi and Bluetooth radios on smartphones provide lim-\\nited accuracy (1 - 3 m) due to the complexities associated with indoor environments,\\nincluding a variety of obstacles (people, furniture, equipment, etc.) and sources of in-\\nterference and noise from other devices [Gu et al. 2009]. Some of these RF positioning\\nsystems use RF location ﬁngerprinting, which requires relatively time consuming site\\nsurvey that may not be feasible for large indoor shopping environments. Therefore, we\\ninvestigated the use of other positioning technology.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 10, 'start_index': 0}, page_content='16:10 J. Ahn et al.\\nOur system uses a commercial image labeling Web service, called IQEngines\\n[IQEngines 2013], to determine the user’s initial starting position when using our\\ngrocery shopping application. IQEngines uses a combination of computer vision and\\ncrowdsourcing to tag a photo with a label describing the content of the image. For\\nexample, an image of a box of Frosted Cheerios cereal might be labeled “General Mills\\nFrosted Cheerios”. When an image is submitted to IQEngines, the image is ﬁrst pro-\\ncessed by a computer vision system in an effort to provide an accurate label. If the\\ncomputer vision system cannot identify the image, then IQEngines passes the image to\\nits crowdsourcing network for analysis and tagging. According to IQEngines, the time\\nto return a label for an image varies from a few seconds for the computer vision sys-\\ntem, to a few minutes for the crowdsourcing system. To ensure fast image labeling in'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 10, 'start_index': 852}, page_content='tem, to a few minutes for the crowdsourcing system. To ensure fast image labeling in\\nour experiments, we have pretrained IQEngines with speciﬁed images and associated\\nlabels for each of the food items in our test environment.\\nTo locate a user within the indoor shopping environment, our mobile application\\nprompts the user to take a picture of the nearest food item using the smartphone. After\\nthis image is submitted to our cloud server, the server submits the image to IQEngines\\nfor labeling. Upon receiving the item label for the image, our server looks up the loca-\\ntion for this item using a spatial database. This spatial database contains the name,\\nlocation, and other associated metadata for each item found in the shopping environ-\\nment. In our grocery shopping application, the coordinate system for item locations\\nis expressed using the following dimensions: aisle number, aisle side (left or right),\\ndivision number, shelf number, and item sequence number. Based on our conversations'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 10, 'start_index': 1764}, page_content='division number, shelf number, and item sequence number. Based on our conversations\\nwith local supermarkets, we have found that this coordinate system is representative\\nof item databases found at some establishments. In this coordinate system, aisles are\\nseparated into 4-foot divisions, and shelves in each aisle are numbered from bottom\\nto top. Items in each location speciﬁed by a tuple of “aisle number, aisle side, division\\nnumber, shelf number” are ordered according to item sequence number. Figure 2 shows\\na graphical representation of this coordinate system for a typical grocery store aisle.\\n4.2. Localizing the User within the Grocery Aisle\\nAs mentioned earlier, our approach is to apply prior work in personalized pedometry\\nto the aisle navigation problem. However, some adaptation is needed for the grocery\\nstore scenario. We observed shoppers’ behavioral patterns as they used our application\\nin grocery stores. We found that the users did not always hold the phone consistently,'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 10, 'start_index': 2670}, page_content='in grocery stores. We found that the users did not always hold the phone consistently,\\nupright, pointed forward down the aisle. The mobile phone’s orientation was often\\nchanged, whenever they moved towards food items recommended by the AR tags of\\nour application. When they moved towards the products they wished to purchase, they\\nusually changed the mobile phone’s orientation, such as holding it down by their side\\nwhile walking or in a strange angle while holding a basket or operating a cart. When-\\never this happened, the accelerometer sensor incorrectly detected a stride. To avoid\\nthese false strides, we modiﬁed the pedometry algorithm to ignore sudden changes in\\nacceleration if they also corresponded with sudden changes in the orientation sensor.\\nAnother modiﬁcation we made to the pedometry algorithm was to limit motion to\\nthe component in the direction parallel to the long axis of the aisle. This is essentially'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 10, 'start_index': 3506}, page_content='the component in the direction parallel to the long axis of the aisle. This is essentially\\n1D map matching, wherein the walls of the aisle form a map that conﬁnes the travels\\nof the user to a set of acceptable paths, or in this case a single path. In this way, our\\nalgorithm cannot misestimate the user as being located within a shelf/wall, and thus\\nour location error is limited to lie only along the long axis of the aisle.\\nTo achieve this, we construct a bounding box around each aisle, where we bound\\nthe range of the x-axis by the width of a regular aisle in the grocery. When the user\\napproaches the edge of the bounding box, for example, the shelves, then we only take\\nthe component of the motion along the axis parallel to the bounding edge, and ignore\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 11, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:11\\nFig. 8. Screenshot of (a) the AR mobile shopping app, (b) the health conditions selection screen activated by\\nclicking the “Health” button, (c) the product information screen activated by clicking on an AR tag associated\\nwith a product, and (d) a typical non-AR grocery list used to compare against the AR UI (see evaluation in\\n5.4).\\nany component of motion perpendicular to the bounding edge. This approach keeps the\\nuser inside the bounding box. In this way, we were able to substantially improve the\\naccuracy of our pedometry-based localization.\\n4.3. AR-Based User Interface\\nOur AR-based user interface is shown in Figure 8(a). AR tags are shown in 3D depth\\nperspective, and are rendered using the OpenGL library. Products that are closer to\\nthe user will have larger tags, while products that are farther away will have smaller\\ntags. To localize the tag next to the related product, we compared the distance on the'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 11, 'start_index': 903}, page_content='tags. To localize the tag next to the related product, we compared the distance on the\\nphone between the product and the user with a distance on a real setting. The depth\\nperspective was adjusted accordingly. Since the tags in our application are displayed in\\n3D space, we are able to adjust the display of the tags according to the angle at which\\nthe user is viewing an item using the phone. When the user looks at the front of the\\naisle, the tags are shown facing the user. If the user turns to the left or right to inspect\\na particular part of the aisle, the tags are automatically rotated to face the user.\\nIn terms of hardware requirements, we found that a phone such as the Sony Nexus\\nOne, which has a 1-GHz processor, 512-MB memory, and 4-GB disk, was sufﬁcient to\\nrun the OpenGL library to render AR objects in real time. In comparison, we found that\\nrunning our application on an older Android phone, a TMobile Mytouch 3G running'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 11, 'start_index': 1762}, page_content='running our application on an older Android phone, a TMobile Mytouch 3G running\\nat 512 MHz, resulting in jerky rendering of AR objects, even after we upgraded from\\nAndroid 1.6 to 2.2.\\n4.3.1. Dietary Food Constraints.People who have diabetes, allergies, hypertension, or\\nother such health issues must often carefully monitor the types of food they buy in\\nthe grocery store. For instance, people with diabetes need to control their sugar level,\\nso they must avoid high-carbohydrate food products that are high in sugar. People\\nwho have allergies, such as peanut or milk allergies, must purchase food products that\\ndo not contain these speciﬁc ingredients. People with hypertension should always try\\nto avoid high-sodium products, in order to maintain their health. Some people may\\nhave multiple diseases or health issues (e.g., diabetes and allergies). Our application\\ncan help people or patients, under the care of a doctor, to monitor their food purchases'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 11, 'start_index': 2629}, page_content='can help people or patients, under the care of a doctor, to monitor their food purchases\\nand intake according to speciﬁc health issues they have. Figure 8(b) shows how a\\nmobile user, with this application on their phone, can select different food ingredient\\nrequirements – such as “low calorie”, “low sodium”, “no milk”, “low fat”, etc.– that are\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 12, 'start_index': 0}, page_content='16:12 J. Ahn et al.\\ntailored to their speciﬁc dietary needs. For example, a user with diabetes, hypertension,\\nand milk allergies would choose “low sugar”, “low sodium”, and “no milk” on this screen.\\nThe mobile application then displays the actual food products on the grocery store\\naisle that are advised or unadvised to buy, with green and red AR tags, respectively.\\nThe application saves these settings, so the user only has to enter them on ﬁrst use,\\nthough the user can change these settings any time. Also, the application supports\\nmultiple conditions, that is, if two conditions are checked and must be avoided, then\\nall recommended products must satisfy both conditions.\\nAs the user walks down the grocery aisle searching for products, she or he can easily\\nget more information about an advised product or a product to avoid by tapping on\\nthe AR tag corresponding to the product that is displayed on the mobile phone. The'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 12, 'start_index': 846}, page_content='the AR tag corresponding to the product that is displayed on the mobile phone. The\\ninformation displayed when the user taps on the tag includes the product’s brand\\nname and brief description, the nutritional information (FDA info), the price, location\\ninformation (shelf number), and the selling rating – related to the store’s record of the\\nfrequency of purchase for the item. Indirectly this comprehensive information about the\\nproduct’s content also provides an indication of the food product’s known or expected\\nﬂavor. The condition of the actual product (e.g., fresh or wilted vegetables) and the\\nmanner in which it has been displayed on the shelf in the grocery store contributes\\nto the user’s impression of the product’s visual appeal. These food quality factors and\\ningredients were identiﬁed as very important to the survey subjects who evaluated our\\napplication as potential real-life users of our system. The graph in Figure 6 shows the'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 12, 'start_index': 1706}, page_content='application as potential real-life users of our system. The graph in Figure 6 shows the\\ndifferent food quality factor ratings that the survey subjects gave for their evaluation\\nof factors they pay most attention to when selecting healthy food products. Figure 8(c)\\nshows an example of the nutritional information displayed when the user taps on the\\nmobile application’s AR tag.\\n4.3.2. Static- and Dynamic-Motion AR Tag Display.The ARFusion application provides\\nusers readable information on the phone regardless of their walking states. When\\na user walks down the grocery aisle with the mobile phone looking for preferred prod-\\nucts, the tags on the phone would normally be shaking from the motion of the user.\\nThe user can have difﬁculty reading the information displayed when she taps on a tag.\\nTo correct for this, we propose two features, static- and dynamic-motion tag display.\\nFirst, the feature for the static-motion tag display is used when the user walks down'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 12, 'start_index': 2589}, page_content='First, the feature for the static-motion tag display is used when the user walks down\\nthe aisle. The application displays the tags in ﬁxed positions whenever the user points\\nthe phone in front of him in the same direction of the aisle the user is walking down. It\\nprovides a static display to the user that the tags can easily be read at ﬁxed positions on\\nthe screen, even though the background may be varying wildly. Second, the feature for\\ndynamic-motion tag display is used when the user is standing approximately station-\\nary on the aisle. At this point, when the user pans the screen and points the camera at\\na product on a shelf, the screen allows tags to change position on the screen and rotate\\nproperly to face the user. To implement this policy, we checked the accelerometer every\\nsecond to detect if there is motion or not, and adapted the AR display accordingly.\\n4.4. Health-Based Grocery Recommendation\\nOur AR-assisted mobile grocery shopping application is designed to make customized'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 12, 'start_index': 3505}, page_content='Our AR-assisted mobile grocery shopping application is designed to make customized\\nrecommendations of healthy grocery products to end users in real time. The recom-\\nmendations need to be customized since shoppers may have different health concerns\\nsuch as food allergies, heart disease, or weight control. The recommendations also need\\nto be generated in real time (while shopper is in a speciﬁc aisle) for them to be useful.\\nThe primary components involved in the recommendation process include the product\\ndatabase, shoppers’ health proﬁles, and recommendation strategies.\\nProducts Database. This database maintains a variety of information regarding each\\nproduct item in the grocery store that may be considered for recommendation. This\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 13, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:13\\ndatabase is usually populated by the store, but extra information may be obtained\\nfrom manufacturer or online databases. Speciﬁc information of importance includes\\nproduct name, ingredients, nutrients, as well as its location in a particular aisle (e.g.,\\nshelf section, level). Since the product items differ signiﬁcantly in terms of ingredients\\nand nutrients, we only consider the ingredients that people may be allergic to and\\ncategorize nutrients into coarser but more intuitive categories such as low calorie, low\\nsodium, etc.\\nHealth Proﬁle. In order to recommend certain items to a shopper, the system must\\nunderstand which items are required or wanted by the user. Furthermore, the system\\nis capable of advising the user against the selection of certain items that have certain\\nnutritional qualities or contain ingredients that may be harmful to him or her (e.g.,'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 13, 'start_index': 855}, page_content='nutritional qualities or contain ingredients that may be harmful to him or her (e.g.,\\ningredients to which the user is allergic). A simple health-based nutrition model was\\nimplemented to support these functionalities for testing the system. The model was\\npopulated with data from two main sources: (1) personal health-based proﬁles of users,\\nfor example, food information and ingredients that a person concerned with his/her\\nweight and who also has a milk allergy might want to purchase for his/her diet or avoid\\naltogether; (2) family health-based proﬁle, for example, food qualities (e.g., calories, fat\\ncontent) family members might prefer and ingredients that the family members may\\nhave been advised by doctors to avoid.\\nRecommendation Strategy. Food recommendation in grocery shopping environments\\nis essentially a “matching” process between a shopper’s health proﬁle and certain food\\nitems in the products database. Based on existing dietary guidelines (e.g., DietGuide-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 13, 'start_index': 1746}, page_content='items in the products database. Based on existing dietary guidelines (e.g., DietGuide-\\nline [2010]), we construct a number of matching rules targeting different health proﬁle\\ncategories and the corresponding food categories to recommend or avoid. At runtime,\\ngiven the shopper’s health proﬁle and current aisle location, the server constructs a\\nlist of food items, each with one of two recommendation labels: recommended means\\nthe item has nutrition needed by the shopper, and warn means the item is in the list\\nof harmful foods associated with the shopper’s health proﬁle. The recommendation\\nresults are then delivered to the shopper’s mobile device for rendering. Note that our\\nrecommendation focuses on satisfying the rules based on the dietary guidelines. While\\nnot a focus of this work, more detailed recommendation strategies can be developed to\\nconsider other factors such as food price, taste, brand name, etc.\\n5. EXPERIMENTAL RESULTS\\n5.1. In-Person Survey Design'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 13, 'start_index': 2665}, page_content='5. EXPERIMENTAL RESULTS\\n5.1. In-Person Survey Design\\nIn order to validate our system, we collected in-person feedback from 15 users. These\\nusers provided us feedback in a couple of ways: First, they were asked to take an\\nonline survey so we could collect some basic demographics and information about their\\nshopping needs and habits and any speciﬁc health/dietary restrictions. Second, users\\ndid an in-person survey with the researcher, after having accompanied the researcher\\nwhile shopping in a grocery store for one hour and using our system on an Android\\nphone. The grocery store we used for our experiments is Lucky’s Market located in\\nBoulder, CO. In this way, we were able to receive immediate verbal feedback from the\\nsubject on how easy and useful our system was to operate. Finally, the users completed\\na satisfaction survey, evaluating how the use of our system could potentially meet their\\nneeds for an improved healthy shopping experience. This user study was approved by'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 13, 'start_index': 3567}, page_content='needs for an improved healthy shopping experience. This user study was approved by\\nthe Institutional Review Board (IRB) [Ahn et al. 2012].\\n5.2. Pedometry-Based Localization\\nThe pedestrian localization via pedometer and heading estimation systems were imple-\\nmented and tested in Java on a Nexus One smartphone running the Android 2.2 (Froyo)\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 14, 'start_index': 0}, page_content='16:14 J. Ahn et al.\\nTable I. Step Detection Accuracy\\nStride Length Measured Steps Actual Steps Error (%)\\nShort 1 28 30 −6.67\\nShort 2 29 30 −3.33\\nShort 3 28 30 −6.67\\nRegular 1 30 30 0.00\\nRegular 2 30 30 0.00\\nRegular 3 29 30 −3.33\\nLong 1 31 30 3.33\\nLong 2 30 30 0.00\\nLong 3 32 30 6.67\\n|Avg.| 3.33\\nStd. Dev. 4.41\\nFig. 9. Overall distance walked.\\noperating system. User tests to evaluate pedometry step detection, stride estimation,\\nand the combination of step detection and stride length estimation into an overall dis-\\ntance walked estimation were carried out. Additionally, different types of users were\\nsimulated, from an “engaged” user who wishes to learn how to use the system to obtain\\nthe best performance, to the “casual” user who is not interested in performance and\\nso uses the system in a careless manner. Further, the method to identify grocery-aisle\\nangle using linear regression on user location history is evaluated.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 14, 'start_index': 860}, page_content='angle using linear regression on user location history is evaluated.\\nTo evaluate pedometry-system step, stride, and distance accuracy, a user was tasked\\nto walk three trials of 30 paces in testing each of three different types of user strides.\\nThe ﬁrst stride type is a “short stride,” which is a deliberately short stride of about\\n50-55 cm. The second stride type is a “medium stride,” which is a comfortable stride\\nlength of about 65-70 cm, which is natural for most users. Lastly, the “long stride” is one\\nthat is the largest the user can manage without jogging or running; a length of about\\n95-100 cm. The results of these nine trials can collectively be seen through Table I and\\nFigures 9 and 10. Table I shows our system to have an overall step-detection error rate\\nof 3.33 percent. In fact, for longer tests that we omit here, step-detection accuracy was\\nshown to improve with the number of strides taken.\\nIn Table I, short strides have tendency for under-detection, while long strides are'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 14, 'start_index': 1773}, page_content='In Table I, short strides have tendency for under-detection, while long strides are\\nprone for over-detection. This is due to the static threshold used for detection, which\\nis tuned for the normal stride length scenario. An adaptive step threshold detection\\nscheme was implemented and tested, but suffered a poorer performance than the static\\nmethod. We theorize this counterintuitive result to be due to the accelerometer’s 10-Hz\\nmaximum sampling rate on the Nexus One smartphone not providing a smooth enough\\ndata curve for the adaptive algorithm to leverage effectively.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 15, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:15\\nFig. 10. Stride length estimation.\\nFigure 10 compares the static and adaptive stride length estimation techniques. The\\nresulting stride lengths represent the average stride length of each of the nine user tri-\\nals completed, calculated by the overall distance measured divided by number of steps\\ndetected, but not actually taken. This removes any additional step-detection errors\\nthat might be present and allow a pure comparison of stride length estimation. Not\\nshown in this ﬁgure is the adaptive stride estimation overall error rate of 2.33 percent,\\nwhile the static stride estimation suffers 17.06-percent error. Interestingly, because\\nthe static method was tuned for the medium stride length, its average error actually\\noutperforms that of the adaptive method on the same data set. A point of note is the\\nextreme accuracy of the long stride under the adaptive estimation scheme. The error'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 15, 'start_index': 881}, page_content='extreme accuracy of the long stride under the adaptive estimation scheme. The error\\nbars are almost too small to be seen, averaging to 99.6-percent stride-length accuracy\\nfor this stride type. This excellent accuracy is most likely due to the ﬂatness of the\\nalpha correction function for large positive peak amplitudes.\\nFigure 9 addresses the combination of error from step detection as well as stride\\nestimation techniques. An overall walk distance is measured by our system and is\\ncompared against the ground truth walked distances. In some cases, for example,\\nadaptive trial 1 for a short stride, an error in step works to reduce the error stride.\\nHowever, in most cases, if both kinds of error are present, they combine with one\\nanother, which is evident by the increase in overall error from stride (2.33 percent) and\\nstep (3.33 percent) to distance walked (3.43 percent).\\nAfter evaluation of the general step, stride, and distance performance character-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 15, 'start_index': 1759}, page_content='After evaluation of the general step, stride, and distance performance character-\\nistics of our system, we turn our attention to the operation of the system given the\\nconstraints of our target environment – the indoors of a grocery store. We look into\\nthe challenges of keeping user location in the aisle of interest, given complex user\\nmovements, and learning about the structure of the indoor environment – for example,\\ngrocery-aisle long-axis orientation – given only the motion sensors of the smartphone.\\nTo our knowledge, no other smartphone pedometry system has addressed the chal-\\nlenges of irregular and highly dynamic movement scenarios capable when a user is\\nbrowsing during shopping. To this end, we evaluate three representative scenarios of\\npossible user movement patterns that vary widely in possible user movement type and\\ncomplexity. In doing so, we additionally stress-test our pedometry-bounded location'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 15, 'start_index': 2597}, page_content='complexity. In doing so, we additionally stress-test our pedometry-bounded location\\nmethod. Further, we examine the beneﬁt of our bounded method in ﬁnding the long\\naxis of a grocery store aisle, which can be done without any knowledge of the unique\\nﬂoor plan of the particular store our user is visiting.\\nWe explore three representative scenarios: a 35-m walk down the long axis of a\\ngrocery store aisle with-return (casual walk), a repetetive circular walk of 2.5-m radius\\n(circle walk), and a bowtie-shaped walk simulating a psuedorandom walk (bowtie walk).\\nThis last scenario, shown in Figure 15 and 16, also serves a second purpose in that we\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 16, 'start_index': 0}, page_content='16:16 J. Ahn et al.\\nFig. 11. Casual walk: Unbounded method. Fig. 12. Casual walk: Bounded method.\\nFig. 13. Circle walk: Unbounded method. Fig. 14. Circle walk: Bounded method.\\nadditionally use the trace to simulate a user’s behavior prior to entering an aisle for\\nthe purposes of shopping under the use of our application – so that we may test our\\nmethod of ﬁnding the aisle long axis orientation information.\\nFirst, we explore the effect of a “casual” user on a walk down and back the length of\\na 35 m long mock grocery store aisle. The test was carried out in lengthy hallway, and\\nso this allowed us to stress-test the system by using a distance longer than is actually\\nfound in normal grocery-store aisles. The user type tested is classiﬁed as “casual,”\\nbecause for this user type, care is not taken to hold the smartphone in a verticle\\norientation, which would offer the highest locationing accuracy. Instead, this user is'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 16, 'start_index': 840}, page_content='orientation, which would offer the highest locationing accuracy. Instead, this user is\\nallowed swing the arm holding the smartphone, introducing a high level of noise data\\nto the sensed user motion. An “engaged” user type was also tested in this scenario,\\nbut it is interesting to note that because the engaged user takes care in obtaining the\\nbest performance from the system, the bounded method was completely unnecessary\\nin offering correction to the location information.\\nIt can be seen in Figure 11 that the user drifts. This drift is caused by both the casual\\nnature of the user type, as well as an inaccurate estimation of the grocery-aisle angle,\\nthat is, the aisle orientation was set to the left of true by 10 degrees. The bounded\\nmodel, Figure 12, shows our systems corrective action under such a scenario. The total\\ndistance walked is shown to be shorter under the bounded method, so some sacriﬁce\\nin accuracy is shown to be incurred, however such increased orientation accuracy is an'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 16, 'start_index': 1750}, page_content='in accuracy is shown to be incurred, however such increased orientation accuracy is an\\nacceptable tradeoff for the distance penalty.\\nFigures 13 and 14 test our system for an erratic circular user walking pattern. Often,\\na browsing shopper will return to a location of interest after initially passing it by. This\\nscenario is very difﬁcult to handle as errors in orientation cumulatively add at each\\nstep. In our test case, we use an engaged user, walking in a circle for four laps. The\\nunbounded method in Figure 13 shows the effects of such orientation drift in which\\nthe user’s virtual location would move across aisle boundaries. The bounded method\\nhandles this scenario very well. By forcing the user’s location to be conﬁned to a speciﬁc\\nblock of ﬂoor space, we avoid such drift.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 17, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:17\\nFig. 15. Bowtie walk: Unbounded method. Fig. 16. Bowtie walk: Bounded method.\\nFinally, Figure 15 and 16 simulate a psuedo-random walk, useful for testing cases\\nin that a user changes orientation direction more than once, which is common under\\na browsing movement. Also useful is this case to simulate user motion before entering\\nan aisle. In Figure 15, we see the true axis of movement is off from the smartphone\\nestimation – if not, the bowtie shape would not be tilted slightly to the right. The\\nbounded method in Figure 16 again corrects for this, while incurring small ﬁner-grained\\nerror as a tradeoff. Further, we simulate the aisle orientation algorithm by plotting\\na linear regression of step points overlayed on each bowtie shape. We show with a\\nminimal collection of points our aisle long axis orientation estimation has good accuracy\\nas shown by the line regression overlayed in the ﬁgures, therefore providing higher'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 17, 'start_index': 915}, page_content='as shown by the line regression overlayed in the ﬁgures, therefore providing higher\\naccuracy for use in the system’s postimage localization mobile AR shopping phase.\\n5.3. Image-Based Positioning\\nThe accuracy of the IQEngines service was tested through taking pictures according\\nto varying angles, as shown in Figure 17. Ten grocery items were photographed at 45,\\n0, and -45 degrees and the pictures were then sent for evaluation to IQEngines, which\\nthen reported back its result. We took one picture straight from the front of the product\\nand took two pictures from the sides – one from the left at a 45-degree angle and one\\nfrom the right at a -45-degree angle. Thirty total pictures were taken and tested. We\\nobserved that the accuracy of IQEngines service was 100 percent in the straight-on and\\nleft cases. However, in the right case, the accuracy was 80 percent, failing to recognize\\nthe product in two of the photos. The product recognition failures of these two photos'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 17, 'start_index': 1803}, page_content='the product in two of the photos. The product recognition failures of these two photos\\noccurred because of the following reasons. First, we took a picture of a product named\\n“Hamburger Helper”, speciﬁcally of the ﬂavor “Chili Cheese”. The IQ Engine service\\ncorrectly recognized the bigger size of “Hamburger Helper”, but incorrectly identiﬁed\\n“Chili Cheese” as “Betty Crocker” instead. Second, we took a picture of a bottle of soy\\nsauce from the right side. The IQEngine service did not read the information since the\\nshape of the bottle, was cylindrical, causing the majority of text to wrap around the\\nbottle, out of view. This bottle passed from the left, because more identifying features\\noccur as part of the beginning of the product name, which is visible from the left. For\\nthese reasons, IQEngines shows worse performance from right-oriented photographs\\nof grocery-store products, but a high accuracy of above 90 percent is still achievable\\noverall.\\n5.4. Real-Grocery Subject Performance'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 17, 'start_index': 2752}, page_content='overall.\\n5.4. Real-Grocery Subject Performance\\nWe evaluated our application’s in-person real-grocery-store functionality by analyz-\\ning the data we collected from the 15 in-person subjects: 87% from men and 13%\\nfrom women. Participants’ age ranged from 18 to 50, with the majority (53%) be-\\ntween 25 and 35 years of age. All results described here provide a comparison be-\\ntween the current visual guiding system being used at Lucky’s Market (referred to as\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 18, 'start_index': 0}, page_content='16:18 J. Ahn et al.\\nFig. 17. IQEngines computer vision product identiﬁcation and label return accuracy.\\nFig. 18. Subject shopping speed without the con-\\nstraint of ensuring the health of the selected product.\\nFig. 19. Subject shopping speed under the constraint\\nof ensuring the health of the selected product.\\nnon-AR-assisted) and our AR-assisted smartphone app. Lucky’s Market includes a two-\\nlevel visual guiding system to direct users to the correct aisle and a customer service\\nkiosk to receive nutritional information. In all our experiments, we did not inﬂuence\\nthe users in any way with respect to how they use the visual guiding system or the\\nnutritional information kiosk.\\nIn Figure 18, we conducted an experiment to measure the efﬁcacy of the AR tags\\ncompared to non-AR-assisted. We asked users to ﬁnd three products in the aisle, with-\\nout regard to any health conditions. The time needed to ﬁnd the three products with'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 18, 'start_index': 847}, page_content='out regard to any health conditions. The time needed to ﬁnd the three products with\\nand without AR was compared. All AR tags were colored green. The experiment was\\nset up so each individual was asked to ﬁnd one set of three products without using\\nour AR-assisted app and another set of three products using the AR tagging. Latency\\ncomparisons are therefore made across users rather than within the same user, since\\nit would not be fair to ask a user to ﬁnd the same three products by another method\\nthat they had just found. Figure 18 shows that for all 15 users that we tested, our\\nAR-assisted tagging resulted in typically much faster performance 2X-3X in ﬁnding\\ngrocery store products. Most non-AR-assisted users in fact exceeded the maximum cap\\nof 5 minutes that we set for the product discovery experiment, and would have taken\\nlonger in practice, so our 2X-3X estimate is a conservative one. Some users were quite'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 18, 'start_index': 1680}, page_content='longer in practice, so our 2X-3X estimate is a conservative one. Some users were quite\\nsavvy in using the list, but even in those cases the AR tagging results in faster discovery\\nof recommended products.\\nIn Figure 19, we conducted an experiment to measure the impact of healthy recom-\\nmendations with and without AR tags. Again, we gave users a list of three products\\nto ﬁnd in the aisle, but in this case, one of the products was unhealthy. In the case of\\nnon-AR-assisted, a user may have to inspect the packaging, the nutrition facts label, or\\nread through the ingredients in order to determine whether a product was unhealthy,\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 19, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:19\\nFig. 20. In-person participants’ satisfaction with aspects of our system: (a) Overall performance, (b) Usabil-\\nity, (c) Speed, (d) UI.\\nthus slowing down their shopping time. In contrast, our AR-based application already\\nperforms this ﬁltering using our health recommendation subsystem on behalf of the\\nuser. Figure 19 shows that even the fast users from the earlier test are now so slowed\\nby checking for healthy conditions that they are unable to ﬁnish within the 5-minute\\ntime limit, whereas in all cases the AR-assisted shopping ﬁnish in 2-1/2 minutes or\\nless.\\nWe also observe that our system remains similarly fast across both health-\\nconstrained and non-health-constrained shopping. Since the health-constrained test\\nwas performed after the health-free test, we hypothesize that users became more fa-\\nmiliar with using our system, so the additional burden of ensuring that products are'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 19, 'start_index': 877}, page_content='miliar with using our system, so the additional burden of ensuring that products are\\nhealthy was compensated for by increased familiarity with our mobile AR system.\\nOur test also examined the improvement our system provides in the identiﬁcation\\nof healthy grocery items, and conversely, the labeling and warning the user against\\npurchasing products potentially unhealthy with respect to the speciﬁc user’s dietary\\nneeds. We found that, when subjects did not use our system, they were actually able\\nto correctly distinguish such healthy products from unhealthy products with perfect\\naccuracy. Similarly, our system also performed with 100-percent healthy versus un-\\nhealthy identiﬁcation. The improvement, however, came with the speed our system\\nwas able to do this versus the increase in time required for the subject to actually read\\nthe ingredient list themselves. Our system required no additional time.\\nFigure 20 shows the average satisfaction rating results. Almost all of the real grocery-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 19, 'start_index': 1784}, page_content='Figure 20 shows the average satisfaction rating results. Almost all of the real grocery-\\nshopping experiment participants (93%) were highly satisﬁed with our system’s overall\\nperformance (5:60%, 4:33%) and the remaining 7% gave it a neutral satisfaction rat-\\ning. About three-fourths (5:46%, 4:27%) of them were also highly satisﬁed with our\\napplication’s usability, and the remaining one-fourth (3:27%) were neutrally satisﬁed.\\nParticipants’ satisfaction with the speed of use of our system in enabling them to ﬁnd\\nhealthy food products quickly was also rated quite highly by 79% of the participants\\n(5:46%, 4:33%). The application’s UI also received high satisfaction ratings from a large\\nmajority of the in-person experiment subjects, with two-thirds of them (5:46%, 4:20%)\\nindicating they were highly satisﬁed with its UI.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 20, 'start_index': 0}, page_content='16:20 J. Ahn et al.\\nFig. 21. Online participants overall satisfaction ratings of our system.\\nFig. 22. Satisfaction ratings for the application screen interface.\\n5.5. On-Line Survey Evaluation of Our Application\\nFinally, we evaluated multiple features of our application based upon the QUIS (Ques-\\ntionnaire for User Interaction Satisfaction) [QUIS 1987] tool’s structure, which is de-\\nsigned to assess users’ subjective satisfaction with speciﬁc aspects of human-computer\\ninterfaces. As part of the survey reported in Section 3.1, the users were asked about\\ntheir overall satisfaction and satisfaction with screen interface, and usability/UI.\\nFigure 21 shows the average rating results for different dimensions (overall-\\nterrible:wonderful, difﬁcult to use:easy to use, slow:fast, dull:stimulating, rigid:ﬂexible,\\nuseless:useful) received from the 104 online participants. Overall, the participants were\\nvery satisﬁed with the features of our system. Three-quarters (74%: wonderful) of them'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 20, 'start_index': 904}, page_content='very satisﬁed with the features of our system. Three-quarters (74%: wonderful) of them\\nwere highly satisﬁed with the system overall and 80% of them indicated our system\\nwas very useful for the purpose it is intended. Over half to more than two-thirds of\\nthem reported it was: easy to use (54%), fast: (63%), stimulating (59%), and ﬂexible:\\n(69%). Only 3-11% of the participants rated these features unfavorably – giving them\\nthe low ratings.\\nNext, we asked participants to evaluate the screen interface: speciﬁcally the read-\\nability of the characters on the screen. Figure 22 shows average rating results. Almost\\ntwo-thirds (62%) of the participants indicated that the characters displayed on the\\nsystem’s screen were easy to read. Three-ﬁfths of the participants (58% and 57%, re-\\nspectively) reported that the organization of information on screen was presented very\\nclearly and the sequences of the screens presented was also quite clear and under-'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 20, 'start_index': 1774}, page_content='clearly and the sequences of the screens presented was also quite clear and under-\\nstandable. Only 5-10% of the participants rated these three features unfavorably.\\nFinally, we collected feedback from the participants on their impressions of the us-\\nability and UI features of our system. We asked them to rate the following features:\\nuse of colors and sounds, system feedback, system messages, and AR-tags, based on\\na 5-point “poor to good” scale. Figure 23 shows the participants’ average satisfaction\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 21, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:21\\nFig. 23. Satisfaction ratings for usability and UI features.\\nrating results. The participants were quite highly satisﬁed with our system’s usability\\nand UI (Use of colors: 77%, System feedback: 60%, System messages: 67%, AR-tags:\\n55%). Only between 2 and 7% of the participants rated these features as functioning\\npoorly (1/2).\\nIn summary, a large majority of the 104 online survey participants who evaluated the\\nvideo demonstration of our system were quite satisﬁed with its overall performance,\\nscreen interface, and usability/UI. In addition, feedback from the 15 in-person survey\\nsubjects who evaluated our system, after using it in a real grocery-store shopping\\nexperience, indicated that they were highly satisﬁed with its functionality. Taking both\\nof these ﬁndings together into consideration, we expect that our system will prove to\\nbe very helpful to food shoppers who need to locate healthy food products in a grocery'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 21, 'start_index': 913}, page_content='be very helpful to food shoppers who need to locate healthy food products in a grocery\\nstore quickly and efﬁciently.\\n5.6. Shopping-Based Personalized Pedometry\\nWe evaluated the shopping-based pedometry algorithm, and focused on the accuracy\\nof the number of footsteps measured with this algorithm, using the accelerometer\\nsensor. When users are looking for products to purchase, they use our application\\nby holding the phone vertically, pointed directly in front of them. Then when they\\nidentify a product to put in their cart or basket, they usually change the mobile phone’s\\norientation as they approach the product – by either placing it on the cart handle,\\ngrasping it with the hand that is holding the basket handle, or by simply moving\\nthe hand that’s holding the phone. We enhanced the pedometry algorithm to enable\\nit to detect these shopping-based behaviors and to reduce the change-in-orientation\\nerrors. We performed an experiment to measure the accuracy of our algorithm’s footstep'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 21, 'start_index': 1820}, page_content='errors. We performed an experiment to measure the accuracy of our algorithm’s footstep\\ndetection, using the pedometry algorithm with ﬁve subjects, who were instructed to\\nhold the phone in each of the 3 positions – on the cart handle, with the basket handle,\\nand in their hand alone in a nonvertical position – as shown in Figure 24. Table II shows\\nthe average footsteps measured and the error rates obtained for the ﬁve subjects who\\nused our application, while walking 100 steps for each of the three phone positions\\ndescribed. The shopping-based personalized pedometry closely determined the actual\\nnumber of footsteps walked in each of the scenarios, with (a) 6.9%, (b) 5.7%, and\\n(c) 4.5% error rates noted in the table. If we approximate each stride as about 3-feet\\nlong, then we’re accumulating errors at a rate of 15 feet every 300 feet walked. The\\ntypical grocery store aisles that we tested in were about 40 feet long, and users did not'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 21, 'start_index': 2674}, page_content='typical grocery store aisles that we tested in were about 40 feet long, and users did not\\nspend 100 strides in a given aisle, so the accumulated error was small enough that it did\\nnot affect the perceived accuracy of overlaying of the AR tags within an aisle. However,\\nmissed strides will accumulate when considering whole-store cross-aisle navigation.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 22, 'start_index': 0}, page_content='16:22 J. Ahn et al.\\nFig. 24. Error rate of shopping-based personalized pedometry for three scenarios: (a) placing the phone on\\nthe cart handle, (b) holding the phone in hand with the basket handle, or (c) holding the phone in hand.\\nTable II. Footstep Detection Accuracy\\nUser Status Measured Avg. Steps Actual Steps Error (%)\\nWith Cart 93.1 100 −6.9\\nWith Basket 94.3 100 −5.7\\nOnly with Hand 95.5 100 −4.5\\n6. CONCLUSION\\nThis article has presented a mobile-based augmented reality system to help improve\\nthe ability of shoppers to ﬁnd healthy food products in a grocery store aisle. We have\\nshown that our application’s color-based AR tagging functionality substantially reduces\\nthe amount of time it takes for shoppers to ﬁnd desired healthy food products and avoid\\nunhealthy ones. We conducted in-store evaluations of our system with 15 users of our\\napplication, and found that mobile AR tagging improved by at least 2X-3X the speed'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 22, 'start_index': 849}, page_content='application, and found that mobile AR tagging improved by at least 2X-3X the speed\\nwith which shoppers could ﬁnd healthy products. We also conducted online surveys\\nwith over 100 subjects and found that 74% were highly satisﬁed with our application\\nand only 3-11% were dissatisﬁed with our application.\\nREFERENCES\\nG. Agapito, B. Calabrese, I. Care, D. Falcone, P. H. Guzzi, N. Ielpo, T. Lamprinoudi, M. Milano, M.\\nSimeoni, and M. Cannataro. 2014. Proﬁling basic health information of tourists: Towards a recom-\\nmendation system for the adaptive delivery of medical certiﬁed nutrition contents. In Proceedings\\nof the 2014 International Conference on High Performance Computing Simulation (HPCS). 616–620.\\nDOI:http://dx.doi.org/10.1109/HPCSim.2014.6903744\\nJunho Ahn, Mike Gartrell, James Williamson, and Richard Han. 2012. ARFusion: An indoor mobile aug-\\nmented reality system supported by pedometry and context-awareness, an AR-assisted grocery shopping'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 22, 'start_index': 1701}, page_content='mented reality system supported by pedometry and context-awareness, an AR-assisted grocery shopping\\napplication. Institutional Review Board on the University of Colorado at Boulder 12-0102.\\nJunho Ahn and Richard Han. 2011. RescueMe: An indoor mobile augmented-reality evacuation system\\nby personalized pedometry. In Proceedings of the IEEE Asia-Paciﬁc Services Computing Conference\\n(APSCC).\\nEileen Anderson, Richard Wientt, Janet Wojcik, Sheila Wientt, and Todd Bowden. 2001. A computerized\\nsocial cognitive intervention for nutrition behavior: Direct and mediated effects on fat, ﬁber, fruits, and\\nvegetables, self-efﬁcacy, and outcome expectations among food shoppers.Ann. Behav. Med.23, 2, 88–100.\\nAmy Barton, Lynn Gilbert, Julaluk Baramee, and Theresa Granger. 2006. Cardiovascular risk in hispanic\\nand non-hispanic preschoolers. National Institute of Health(May-June 2006).\\nStephane Beauregard. 2007. Omnidirectional pedestrian navigation for ﬁrst responders. In Proceedings of'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 22, 'start_index': 2684}, page_content='the 4th Workshop on Positioning, Navigation and Communication (WPNC’07).\\nJ. Bobadilla, F. Ortega, A. Hernando, and A. Guti ´eRrez. 2013. Recommender systems survey. Know.-Based\\nSyst. 46 (2013), 109–132. DOI:http://dx.doi.org/10.1016/j.knosys.2013.03.012\\nCristina Botella, Juani Breton-Lopez, Soledad Quero, Rosa Banos, Azucena Garcia-Palacios, Irene Zaragoza,\\nand Alcaniz Raya. 2011. Treating cockroach phobia using a serious game on a mobile phone and aug-\\nmented reality exposure: A single case study.Comput. Hum. Behav.27, 1, 217–227.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 23, 'start_index': 0}, page_content='Supporting Healthy Grocery Shopping via Mobile Augmented Reality 16:23\\nDanKam. 2010. DanKam AR application for color blindness. http://news.cnet.com/8301-27080 3-20026054-\\n245.html.\\nDietGuideline 2010. U.S. Department of Agriculture. 2010 Dietary guidelines for Americans. http://www.\\ncnpp.usda.gov/DGAs2010-PolicyDocument.htm. (2010).\\nJill Freyne and Shlomo Berkovsky. 2010. Intelligent food planning: Personalized recipe recommendation.\\nIn Proceedings of the 15th International Conference on Intelligent User Interfaces (IUI’10). 321–324.\\nDOI:http://dx.doi.org/10.1145/1719970.1720021\\nChristoph Fuchs, Nils Aschenbruck, Peter Martini, and Monika Wieneke. 2011. A survey on indoor tracking\\nfor mission critical scenarios. Perva. Mobile Comput.7, 1.\\nSubhashini Ganapathy, Glen Anderson, and Igor Kozintsev. 2011. MAR shopping assistant usage: Delay,\\nerror, and utility. InProceedings of the IEEE Virtual Reality Conference (VR). 207–208.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 23, 'start_index': 850}, page_content='error, and utility. InProceedings of the IEEE Virtual Reality Conference (VR). 207–208.\\nGolfscape. 2014. Golfscape GPS AR range ﬁnder. http://golfscapeapp.com/.\\nGoogleDocs 2014. Google Docs’ survey tool. http://support.google.com/docs/bin/answer.py?hl=en&answer=\\n87809.\\nLevent G ¨org ¨u, Abraham Campbell, Kealan McCusker, Mauro Dragone, Michael O’Grady, Noel O’Connor,\\nand Greg O’Hare. 2010. FreeGaming: Mobile, collaborative, adaptive and augmented exergaming. In\\nProceedings of the 8th International Conference on Advances in Mobile Computing and Multimedia\\n(MoMM’10). 173–179.\\nYanying Gu, Anthony Lo, and Ignas Niemegeers. 2009. A survey of indoor positioning systems for wireless\\npersonal networks. IEEE Commun. Surv. Tutori.11, 1, 13–32.\\nRam´on Herv´as, Alberto Garcia-Lillo, and Jos´e Bravo. 2011. Mobile augmented reality based on the semantic\\nweb applied to ambient assisted living. InAmbient Assisted Living, Jos Bravo, Ramn Hervs, and Vladimir'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 23, 'start_index': 1805}, page_content='Villarreal (Eds.), Lecture Notes in Computer Science, vol. 6693, Springer Berlin / Heidelberg, 17–24.\\nHwajung Hong, Hee Young Jeong, Rosa I. Arriaga, and Gregory D. Abowd. 2010. TriggerHunter: Designing\\nan educational game for families with asthmatic children. In Proceedings of CHI EA ’10. 3577–3582.\\nIQEngines. 2013. IQEngines: Image recognition and visual search. http://www.iqengines.com.\\nVaiva Kalnikaite, Yvonne Rogers, Jon Bird, Nicolas Villar, Khaled Bachour, Stephen Payne, Peter Todd,\\nJohannes Schoning, Antonio Kruger, and Stefan Kreitmayer. 2011. How to nudge in Situ: Designing\\nLambent devices to deliver salience information in supermarkets. In Proceedings of UbiComp’11.\\nDavid Katz, Valentine Njike, Zubaida Faridi, Lauren Rhee, Rebecca Reeves, and David Jenkins. 2009. The\\nstratiﬁcation of foods on the basis of overall nutritional quality: The overall nutritional quality index.\\nAmer . J. Health Promot.(Nov.–Dec. 2009).'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 23, 'start_index': 2701}, page_content='Amer . J. Health Promot.(Nov.–Dec. 2009).\\nStefan Ladstaetter, Patrick Luley, Alexander Almer, and Lucas Paletta. 2010. Multisensor data fusion for\\nhigh accuracy positioning on mobile phones. In Proceedings of MobileHCI. 395–396.\\nJia-Kuan Lin, Po-Hsun Cheng, Yen Su, et al. 2011. Augmented reality serious game framework for reha-\\nbilitation with personal health records. In Proceedings of the 13th IEEE International Conference on\\ne-Health Networking Applications and Services (Healthcom). IEEE, 197–200.\\nT. Lobstein and S. Davies. 2009. Deﬁning and labeling ‘healthy’ and ‘unhealthy’ food.Public Health Nutr .\\n(2009).\\nJennifer Mankoff, Gary Hsieh, Ho Chak Hung, Sharon Lee, and Elizabeth Nitao. 2002. Using low-cost sensing\\nto support nutritional awareness. In Proceedings of the 4th International Conference on Ubiquitous\\nComputing. Springer-Verlag, 371–376.\\nMechanicalTurk 2014. Amazon Mechanical Turk Survey Services. https://www.mturk.com/mturk/.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 23, 'start_index': 3562}, page_content='MechanicalTurk 2014. Amazon Mechanical Turk Survey Services. https://www.mturk.com/mturk/.\\nCliona Ni Mhurchu, Tony Blakely, Joanne Wall, Anthony Rodgers, Yannan Jiang, and Jenny Wilton. 2007.\\nStrategies to promote healthier food purchases: A pilot supermarket intervention study. Public Health\\nNut. 10, 06, 608–615.\\nBarry Mulrooney, Mair´ead McDermott, and Nick Earley. 2006. NutraStick: Portable diet assistant. InCHI’06\\nextended abstracts on Human factors in computing systems (CHI EA ’06). ACM, New York, 1855–1860.\\nDOI:http://dx.doi.org/10.1145/1125451.1125802\\nYoosoo Oh, Ahyoung Choi, and Woontack Woo. 2010. u-BabSang: A context-aware food recommendation\\nsystem. J. Supercomput.54, 1, 61–81. DOI:http://dx.doi.org/10.1007/s11227-009-0314-5\\nPCAST. 2010. Realizing the full potential of health information technology to improve healthcare for amer-\\nicans: The path forward. http://www.whitehouse.gov/sites/default/ﬁles/microsites/ostp/pcast-health-it-\\nreport.pdf. (2010).'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 23, 'start_index': 4518}, page_content='report.pdf. (2010).\\nM. Phanich, P. Pholkul, and S. Phimoltares. 2010. Food recommendation system using clustering analysis for\\ndiabetic patients. InProceedings of the International Conference on Information Science and Applications\\n(ICISA). 1–8. DOI:http://dx.doi.org/10.1109/ICISA.2010.5480416\\nQUIS 1987. Questionnaire for user interaction satisfaction. http://lap.umd.edu/quis/about.html.\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.'),\n",
       " Document(metadata={'source': 'data\\\\healthy_grocery_via_ar.pdf', 'page': 24, 'start_index': 0}, page_content='16:24 J. Ahn et al.\\nSkyMap. 2011. Google Sky Map AR astronomy application. http://www.google.com/mobile/skymap/.\\nRichard Wientt, Eileen Smith Anderson-Bill, Patricia G. Bickley, Janet Walberg-Rankin, John F. Moore,\\nand Michael Leahy. 1997. Nutrition for a Lifetime System c⃝: A multimedia system for altering food\\nsupermarket shoppers’ purchases to meet nutritional guidelines.Comput. Hum. Behav.13, 3, 371–392.\\nDOI:http://dx.doi.org/DOI: 10.1016/S0747-5632(97)00015-0\\nWordLens. 2014. WordLens augmented reality language translation app for the iPhone. http://www.\\nquestvisual.com/.\\nReceived January 2015; revised April 2015; accepted June 2015\\nACM Trans. Multimedia Comput. Commun. Appl., Vol. 12, No. 1s, Article 16, Publication date: October 2015.\\nView publication stats'),\n",
       " Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt', 'start_index': 0}, page_content=\"D. Food Ingredient Databases:\\nAccessible and comprehensive food ingredient databases are a benchmark for mobile applications meant to\\nenhance dietary choices and outcomes. It contains detailed data of food products, among which are the\\ningredients, nutritional values, and potential allergens. [4] One such example includes the open source\\ndatabase known as Open Food Facts, containing over 50,000 entries of food products present in 134\\ncountries. [5] However, often, custom databases need to be created with regard to specific requirements so\\nthat local food products may be covered. [8] \\nOne is PHARA, which uses a client-server architecture with a MongoDB database to implement\\nrecommendations of healthy foods. The database contains items as well as user profiles. It feeds this\\ninformation into the application's recommendation engine whereby consumers marked out healthier foods\\nthey liked and wanted by preference and need[5].\"),\n",
       " Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt', 'start_index': 886}, page_content=\"they liked and wanted by preference and need[5].\\nAnother application is regarding ingredient analysis especially concerning food allergies. This is done using\\na barcode scanner and OCR by scanning the ingredients against a food and health database having known\\nallergens. Ingredients scanned will alert the users on those materials that can cause allergic reactions. [5] \\nARFusion is the grocery shopping application enabled with AR based on a health-based model of nutrition,\\nand has personal and family profiles filled into it. It requires relating data from product database tracking\\ninformation of every product's ingredient, nutrient, and the location in the grocery, which information allows\\nthe application to make real-time personalized recommendations on healthy products. [9] \\nMoreover, the substitution of ingredients is performed using knowledge graphs. One such system was\\ncreated based on a knowledge graph called FoodKG which interconnected the ingredients with the food\"),\n",
       " Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt', 'start_index': 1772}, page_content='created based on a knowledge graph called FoodKG which interconnected the ingredients with the food\\nontology named FoodOn and even nutritional information by USDA. This system points out healthy\\nalternatives according to dietary restrictions. [10] \\nTherefore, there is a great need to establish such comprehensive food ingredient databases that would be\\naccessible for consumers so that they might choose their foods wisely, where they would enjoy better habits\\nof consumption and general well-being. [4] \\nE. UI/UX in Food-Related Mobile Applications: A Balancing Act\\nBut of both, what shines through is the role that well-designed UIs and UXs play especially for the mobile\\napplications concerning food. Rather more salient considerations piling too much information on users or\\ntaking them through complicated navigation is more nuisance to engagement and effectiveness resulting\\nfrom balancing clamor for quick and easy access of such applications.'),\n",
       " Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt', 'start_index': 2654}, page_content='from balancing clamor for quick and easy access of such applications. \\nOne of the ways through which complicated information can be made accessible is through visual, such as\\ncolor-coded tags and intuitive layouts. The result of the study was that the color-coded AR tags were very\\neasy for the users to distinguish between the healthy and unhealthy products. The developers of the\\nPHARA attempted to develop modular visual parts that would pass relevant information in a clear-cut\\nCureus Journal of Computer Science\\n5 of 12\\nmanner. Figure 8 of this source shows several layouts of PHARA in making food product information\\nunderstandable. [3]  \\nFor example, the design of a mobile application concerning the ingredient analysis is essential to make sure\\nit becomes user friendly, considering there are food allergic users who might at some point require\\nassistance. The interface of the application focused on simplicity in daily use. [3]'),\n",
       " Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt', 'start_index': 3508}, page_content='assistance. The interface of the application focused on simplicity in daily use. [3] \\nTherefore, developers have to face the specific functional-related issues pertaining to such applications. For\\nexample, food scanner applications require one to scan the barcodes of each article purchased in the\\nmarket. It is cumbersome and time-consuming in the process. These features, combined with overall\\ninformation regarding nutritional content usually available, pose a burdensome job for the user to go through\\nthe information and take the right decisions. [3] \\nOn the contrary, FOP labels present a much less complicated approach. FOP labeling acquires the real\\nsimplified nutritional information on product packaging. This ease of access and processing becomes a\\ngood reason why FOP labels are more effective in determining consumer choices compared to food scanner\\napps. [11] \\nAnother great UI/UX is restaurant AR menus. With restaurant AR, the wish of the customers can be'),\n",
       " Document(metadata={'source': 'data\\\\food_ingredient_dataset.txt', 'start_index': 4383}, page_content=\"Another great UI/UX is restaurant AR menus. With restaurant AR, the wish of the customers can be\\nsatisfied with three-dimensional images of dishes and even whole lists of ingredients; the menu can be\\ninteractive. The value of the information should be conserved rather than speed up the generation of the\\ncontent. In order to get success, the entire AR experience has to be intuitive as well as informative. [4] \\nMore generally, the sources emphasize that the development of successful food-related mobile apps will\\nrequire special attention to UI/UX principles. Balancing 'complexity' of features with the need for a seamless\\nuser experience is key to user engagement and, in the end, the impact of the app toward changing users'\\nhealthy choices.\"),\n",
       " Document(metadata={'source': 'data\\\\ar_influence_on_market.md', 'start_index': 0}, page_content=\"AR's Influence on Consumer Behavior: Potential and Pitfalls\\n\\nSources investigate the effects of Augmented Reality on consumer behavior, from developing the shopping experience to more challenges entailed in increasing complexity and ease of use. Although AR brings some innovative ways of interaction with the consumer in order to provide information, effectiveness is lower than the other, much more common influences, such as FOP labels.\\n\\nImproving Food Choices Using Augmented Reality\"),\n",
       " Document(metadata={'source': 'data\\\\ar_influence_on_market.md', 'start_index': 441}, page_content='Improving Food Choices Using Augmented Reality\\n\\nA number of studies demonstrate the potential of AR to encourage healthier food choices. A study [9] explored the feasibility of an AR application which gives users personalized suggestions of healthy products to purchase in supermarkets. The application identified shelf products and overlaid color-coded flags, thus allowing users to point out healthy foods quickly along with bad ones to avoid. Another app [1] aimed to guide consumers toward making healthier selections focusing on diet. It relied on the color-coded classification between healthy and unhealthy foods.\\n\\nSource [11] would propose an AR application, PHARA, to aid in grocery store food product choice decision-making. The application of AR is applied to represent information about food products to a user. Another study [1] uses a mobile application-based AR, which provides information to consumers on products using AR and suggests healthy and similar products to people.'),\n",
       " Document(metadata={'source': 'data\\\\ar_influence_on_market.md', 'start_index': 1434}, page_content='Furthermore, researchers [12] conducted four studies to investigate the influence of a food scanner app (Yuka) on consumer choice. They found that, whereas the app increased intentions to buy healthier products in hypothetical situations, it had no impact on real behavior in the grocery store itself during an experimental supermarket setting. This gap between intentions and actual choices also points to the effort which may be required to utilize it while shopping, thus constituting a barrier toward the effectiveness of the application of the app.\\n\\nAR vs Conventional Techniques\\n\\nAll these sources point out that in almost all conditions, consumer behavior affects AR interventions less compared to the traditional methods such as FOP labeling. A comparative study [7] where a head-to-head comparison of the app on the food scanner versus FOP labeling came out indicated that in all situations, FOP labeling always outscored the application.\\n\\nReasons for Differences in Performance:'),\n",
       " Document(metadata={'source': 'data\\\\ar_influence_on_market.md', 'start_index': 2383}, page_content=\"Reasons for Differences in Performance:\\n\\nThere are several reasons that can explain differences in performance. FOPs give consumers a look from the front of the package nutrition information directly accessible and easy to process. With AR applications, especially if they require scanning the barcode, their use will require more effort from the user—which may interfere with the proper processing of the information or even reduce the making of an informed choice.\\n\\nSource [13] concludes that food scanner apps are ineffective as substitutes for FOP labels since the information is far more extensive and multiple scans are required for comparison of packaged products. Such multilevel processing of information might, in turn, sub-optimally affect consumers' choices.\\n\\nPotential Applications and Future Directions\\n\\nSources admit that, despite the problems in AR, it has uses and future directions.\"),\n",
       " Document(metadata={'source': 'data\\\\ar_influence_on_market.md', 'start_index': 3201}, page_content='Sources admit that, despite the problems in AR, it has uses and future directions.\\n\\nAR can be used to create interactive menus in restaurants so that customers can view three-dimensional visualizations of the dishes and the lists of ingredients in detail [4]. It may enhance customer engagement and possibly your customer choice.\\n\\nAR can be embedded in food packaging so that consumers get a rich interaction experience [4]. Scanning the packaging shall unlock for users information regarding the nutritional data, the origin, and the process of manufacture along with virtual representations of the food. Such enhanced transparency and engagement might impact the purchasing decision.\\n\\nAR applications can be further developed to aid in new food product development [4]. Developers can easily identify possible problems and then optimize a product for actual production by virtue of virtualization of the product followed by its analysis in real environments or simulated environments.'),\n",
       " Document(metadata={'source': 'data\\\\ar_influence_on_market.md', 'start_index': 4189}, page_content='Further studies may be conducted to ascertain whether AR with other modes like FOP labels push consumers toward healthier diets [14]. Perhaps, in isolation, the strategy can do little but when merged, the constraints are crossed, and intervention becomes that much stronger. All levelled off, taken broadly, in a rather convex shape to reveal the impact of AR on consumer behavior. Promises of AR about enhancing shopping experiences and healthy choices seem alluringly good but simplifying complexity and ease of use seem the biggest hurdles. Further research and development of optimal applications are required in their realization as regards their potential in shaping consumer behavior.'),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 0}, page_content='Introduction And Background\\nINTRODUCTION\\nIt has been richly noted that information technology could catalyze an important set of benefits in the\\nhealthcare area which would include improving the quality and reducing the cost of healthcare. The\\nemergence of sensor-rich powerful smart phones to provide a rich set of user contextual information in real\\ntime made it feasible to provide effective and affordable healthcare to nearly everyone via smartphones.\\nMore specifically, well-designed mobile phone applications can empower individuals to proactively embrace\\nhealth and wellness. No longer is the health care system made of a reactive system or placed sitting back\\nwaiting for medical attention to surface via an ER visit. What once belonged to the clinic is now patient-\\ncentered care. What once focused on the disease agenda is now wellness in health care.\\nBased on the sheer number of excellent justifications for applying smartphones, cloud computing, mobile'),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 967}, page_content=\"augmented reality and other information technologies to improve health and well-being in society, this paper\\nexamines the interactive, creative, and user-friendly health mobile applications. Previous studies have\\nclearly established a correlation between low levels of nutritional intake and the rising prevalence of\\nunhealthy conditions such as obesity and lifestyle diseases such as heart disease and diabetes. A lack of\\nhealthy food consumption coupled with physical inactivity is two key causes of an epidemic of overweight\\npersons and cases of obesity in the United States. The betterment of a person's diet begins with the\\nbetterment of the nutritional quality of food he or she chooses. This makes it nearly impossible for the\\naverage consumer to make better choices when a food supply contains tens of thousands of processed and\\npackaged foods with different messages on bags, boxes, bottles, jars, and cans. Consumers report they\"),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 1906}, page_content=\"know what is healthy and what isn't, but say they are confused over how to implement general nutritional\\nadvice.\"),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 2023}, page_content='The application of technology in diet management has been perceived as a useful tool and resource in\\nhelping to reduce poor health conditions and foster good well-being generally among people. Mobile\\naugmented reality in supermarkets is one of the proposed solutions to this very pressing problem of\\nenriching the quality of nutrition in food choices while shopping at the point-of-sale. One of the more\\ninteresting emerging technologies AR exemplifies, in very simple words, simply offers rich visual interaction\\nwith the real world by overlaying or augmenting the elements the camera view contains with useful\\ninformation with relevance to the objects appearing in the video screen of the camera. With an AR-based\\nsmartphone application, the user now experiences a direct interactive or context-rich experience. Actually, it\\nis just recently that AR gained much mindshare as an exciting new technology for the mobile smartphone.[1]'),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 2957}, page_content='Some examples of such applications are an augmented reality range finder for golf lovers, Cape GPS\\nRangefinder; AR application for color-blind people; Google Sky Map, that is an AR application for amateur\\n1 1 1 1\\n1'),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 3176}, page_content='Cureus Journal of Computer Science \\nOpen Access Review\\nArticle\\nHow to cite this article'),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 3265}, page_content='astronomers; Word Lens, that translates a foreign language captured by the mobile camera and overlays\\nthe result on top of the text; and many more. As the user continues walking down an aisle to get an item, its\\nAR tag grows in size. When the tags of the thing are clicked, it provides nutrition information about that\\nproduct. Tags are colored. Therefore, for example, green would be nutritionally preferable items-low calorie\\nand gluten-free. Red would be used to mark bad products to avoid. For example, those that have a high\\ncholesterol level or peanut contents. Additionally, the consumers can upload health profiles that might have\\nan influence on their purchasing of food products such as weight watch, heart condition, and food allergies,\\netc. We observe that the product to be recommended will differ because the user has provided an input\\nhealth condition/cue. To our knowledge system, we strongly believe that we are the first ones that introduce'),\n",
       " Document(metadata={'source': 'data\\\\introduction_and_background.docx', 'start_index': 4224}, page_content='AR tagging with pedometric-based localization along with back-end health-based grocery recommendation\\nat point of purchase.\\nPoint-of-purchase nutrition information probably would have greater impacts on dietary quality because it\\nbetter primes consumers for decisions about healthy foods than the traditional generic messages of \"eat\\nbetter.\".\\nWe installed our system in an actual grocery aisle of a real store to see how easy and quick subjects\\nreported finding healthy food products and avoiding unhealthy ones using our application with AR tagging.\\nIn addition, we have tested the functionality and performance of our application based on the data that we\\nhave accumulated from 104 participants of our online demonstration/survey.'),\n",
       " Document(metadata={'source': 'data\\\\ingredient_substituent.html', 'start_index': 0}, page_content='Ingredient Substitutions and FoodKG\\n\\nA comprehensive approach to ingredient substitutions and healthy alternatives using FoodKG and DIISH heuristic.\\n\\nIngredient Substitutions\\n\\nSource [10] has examined all possible identification directions and the suggestion of ingredient alternatives. FoodKG is described as a knowledge graph that allows ranking the most plausible alternatives for explicit semantic information, as well as the implicit semantics captured by word embeddings, leading users toward healthy choices based on dietary requirements and preferences.\\n\\nFoodKG: A Food Knowledge Graph\\n\\nFoodKG is a knowledge graph of recipes and their ingredients, sourced from various references:\\n\\nFood Category: FoodKG utilizes knowledge from the FoodOn ontology to classify ingredients.\\n\\nNutritional Content: FoodKG associates ingredients with USDA data, offering detailed nutritional information (calories, macronutrients, and micronutrients).'),\n",
       " Document(metadata={'source': 'data\\\\ingredient_substituent.html', 'start_index': 941}, page_content='Recipes: FoodKG includes various recipes, enabling analysis of ingredient occurrences and recipe contexts.\\n\\nFigure 4 and reference [15] show how FoodKG links ingredient information with FoodOn ontology and USDA nutritional data:\\n\\nNaming Target Ingredients and Healthy Alternatives\\n\\nFoodKG helps identify ingredients to replace based on dietary restrictions. The system considers:\\n\\nIngredient Type Restrictions: Based on FoodOn’s class hierarchy, it automatically infers proscribed ingredients (e.g., meat for vegetarians).\\n\\nNutritional Content Constraints: The app computes the nutritional content using USDA data to highlight ingredients contributing to restricted nutrients.\\n\\nRanking Possible Substitutions: The DIISH Heuristic\\n\\nSource [8] introduces the Diet-Improvement Ingredient Substitutability Heuristic (DIISH), which combines explicit and implicit semantics using word embeddings like Word2Vec and spaCy. DIISH uses four scoring metrics:'),\n",
       " Document(metadata={'source': 'data\\\\ingredient_substituent.html', 'start_index': 1890}, page_content=\"Co-occurrence Similarity: Measures the co-occurrence of ingredients in recipes.\\n\\nRecipe Context Similarity: Captures the similarity in recipe contexts between the target ingredient and potential substitutes using PPMI.\\n\\nThese scores are combined into a ranking formula that suggests meaningful ingredient substitutes, excluding ingredients that are superclasses or subclasses of the target.\\n\\nEvaluation and Sample Results\\n\\nDIISH’s effectiveness was tested using three datasets, demonstrating superior performance compared to baselines. The following table shows some substitution examples:\\n\\nTarget Ingredient Ground-Truth Substitutes DIISH's Top 5 Ranked Substitutes Arugula Watercress, Belgian endive, Radicchio, Escarole Watercress, Frisee, Radicchio, Romaine lettuce, Butter lettuce Lard Vegetable oil, Shortening, Margarine, Bacon fat Vegetable shortening, Shortening, Margarine, Bacon fat, Butter\\n\\nExample Use Case: Diabetic Patient\"),\n",
       " Document(metadata={'source': 'data\\\\ingredient_substituent.html', 'start_index': 2793}, page_content='Example Use Case: Diabetic Patient\\n\\nSource [15] demonstrates the application of DIISH for a diabetic patient seeking to reduce carbohydrate intake. The system suggests healthier substitutes for potatoes:\\n\\nRanked Substitutes Carbohydrates per 100g Turnip 6.4g Squash 6.9g Cauliflower 5.0g Butternut squash 11.7g Zucchini 3.1g\\n\\nCustom Databases and Local Food Products\\n\\nIn addition to FoodKG, custom databases tailored for local food products have been developed, such as a mobile app that combines barcode scanning with OCR technology to identify food ingredients and provide health advice. This app supplements information from open-source databases like Open Food Facts [17].\\n\\nReferences:\\n\\n[10] Source on ingredient identification and suggestions.\\n\\n[15] FoodKG and DIISH heuristic references.\\n\\n[17] Open Food Facts for local food data.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if \"id\" in chunk.metadata:\n",
    "            continue\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        if \"page\" not in chunk.metadata:\n",
    "            chunk.metadata[\"page\"] = 0\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_chroma(chunks,embedding_function,CHROMA_PATH=CHROMA_PATH):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "    \n",
    "    # remove chunks which are not in chunk with ids but are in database\n",
    "    deleted_chunks = existing_ids - set(chunk.metadata[\"id\"] for chunk in chunks_with_ids)\n",
    "    if len(deleted_chunks):\n",
    "        print(f\"👉 Deleting documents: {len(deleted_chunks)}\")\n",
    "        db.delete(ids=list(deleted_chunks))\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"👉 Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "    else:\n",
    "        print(\"✅ No new documents to add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_db(CHROMA_PATH=CHROMA_PATH):\n",
    "    # delete if previous exists\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 266\n",
      "👉 Deleting documents: 94\n",
      "✅ No new documents to add\n"
     ]
    }
   ],
   "source": [
    "add_to_chroma(texts,hugging_face_ef)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
